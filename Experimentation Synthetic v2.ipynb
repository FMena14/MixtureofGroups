{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation on the Syntetic simmulated data and annotators\n",
    "* batch = 128\n",
    "* delta convergence = 1e-2\n",
    "* Optimizer = ADAM\n",
    "\n",
    "* Our proposed: Pre-train base model with hard-MV (5 epochs?) as Rodrigues: https://github.com/fmpr/CrowdLayer/blob/master/demo-conll-ner-mturk.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras, time, sys, os, gc\n",
    "from keras.models import clone_model\n",
    "\n",
    "DTYPE_OP = 'float32'\n",
    "keras.backend.set_floatx(DTYPE_OP)\n",
    "\n",
    "if DTYPE_OP == 'float64':\n",
    "    keras.backend.set_epsilon(np.finfo(np.float64).eps)\n",
    "elif DTYPE_OP == 'float32':\n",
    "    keras.backend.set_epsilon(np.finfo(np.float32).eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GLOBAL Variables\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS_BASE = 50\n",
    "OPT = 'adam' #optimizer for neural network \n",
    "TOL = 1e-2 #tolerance for relative variation of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2292, 2)\n"
     ]
    }
   ],
   "source": [
    "folder = \"..\" #same as refered below..\n",
    "\n",
    "X_train = np.loadtxt(folder+\"/syntetic/simple/datasim_X_train.csv\",delimiter=',')\n",
    "Z_train = np.loadtxt(folder+\"/syntetic/simple/datasim_Z_train.csv\",dtype='int') #groudn truth\n",
    "\n",
    "X_test = np.loadtxt(folder+\"/syntetic/simple/datasim_X_test.csv\",delimiter=',')\n",
    "Z_test = np.loadtxt(folder+\"/syntetic/simple/datasim_Z_test.csv\",dtype='int') #groudn truth\n",
    "\n",
    "print(\"Input shape:\",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2292, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std= StandardScaler(with_mean=True) #matrices sparse with_mean=False\n",
    "std.fit(X_train)\n",
    "Xstd_train = std.transform(X_train)\n",
    "Xstd_test = std.transform(X_test)\n",
    "Xstd_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta Convergence criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code.learning_models import LogisticRegression_Sklearn,LogisticRegression_Keras,MLP_Keras\n",
    "#deep learning\n",
    "from code.learning_models import default_CNN,default_RNN,default_RNNw_emb,CNN_simple, RNN_simple\n",
    "\n",
    "from code.utils import EarlyStopRelative\n",
    "ourCallback = EarlyStopRelative(monitor='loss',patience=1,min_delta=TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcdc73b59e8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upper bound model\n",
    "Z_train_onehot = keras.utils.to_categorical(Z_train)\n",
    "\n",
    "model_UB = MLP_Keras(Xstd_train.shape[1:],Z_train_onehot.shape[1],8,1,BN=False,drop=0.2)\n",
    "\n",
    "model_UB.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "model_UB.fit(Xstd_train,Z_train_onehot,epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0,callbacks=[ourCallback])\n",
    "\n",
    "evaluate = Evaluation_metrics(model_UB,'keras',Xstd_train.shape[0],plot=False)\n",
    "Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred)\n",
    "Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)\n",
    "\n",
    "results1[0].to_csv(\"synthetic_UpperBound_train.csv\",index=False)\n",
    "results2[0].to_csv(\"synthetic_UpperBound_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mean_dataframes(df_values):\n",
    "    if df_values[0].iloc[:,0].dtype == object:\n",
    "        RT = pd.DataFrame(data=None,columns = df_values[0].columns[1:], index= df_values[0].index)\n",
    "    else:\n",
    "        RT = pd.DataFrame(data=None,columns = df_values[0].columns, index= df_values[0].index)\n",
    "        \n",
    "    data = []\n",
    "    for df_value in df_values:\n",
    "        if df_value.iloc[:,0].dtype == object:\n",
    "            data.append( df_value.iloc[:,1:].values )\n",
    "        else:\n",
    "            data.append(df_value.values)\n",
    "    RT[:] = np.mean(data,axis=0)\n",
    "    \n",
    "    if df_values[0].iloc[:,0].dtype == object:\n",
    "        RT.insert(0, \"\", df_values[0].iloc[:,0].values )\n",
    "    return RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code.representation import *\n",
    "from code.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code.baseline import LabelInference\n",
    "from code.baseline import RaykarMC\n",
    "from code.MixtureofGroups import GroupMixtureOpt\n",
    "from code.MixtureofGroups import project_and_cluster,clusterize_annotators\n",
    "from code.evaluation import Evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_seted = 3 #arg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code.generate_data import SinteticData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GenerateData = SinteticData()\n",
    "GenerateData.set_probas(asfile=True,file_matrix='../syntetic/simple/matrix_datasim_normal.csv',file_groups ='../syntetic/simple/groups_datasim.csv')\n",
    "Tmax = 100\n",
    "T_data = 10 \n",
    "y_obs, groups_annot = GenerateData.sintetic_annotate_data(Z_train,Tmax,T_data,deterministic=False)\n",
    "\n",
    "\n",
    "real_conf_matrix = GenerateData.conf_matrix\n",
    "\n",
    "if len(groups_annot.shape) ==1 or groups_annot.shape[1] ==  1: \n",
    "    groups_annot = keras.utils.to_categorical(groups_annot)  #only if it is hard clustering\n",
    "    print(\"Done\")\n",
    "confe_matrix = np.tensordot(groups_annot,real_conf_matrix, axes=[[1],[0]])\n",
    "\n",
    "del GenerateData\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scenario = 1  #arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Synthetic data is being generated...Done! \n",
      "Shape (data,annotators):  (2292, 100)\n",
      "Classes:  3\n",
      "num Patients: 2292\n",
      "Iter\tlog-likelihood\tdelta-CM\tdelta-ER\tdelta-LL\n",
      "1 \t -15413.840275687367\n",
      "2 \t -11978.084033037498 \t0.5473\t0.387760\t0.222901\n",
      "3 \t -11602.744457754245 \t0.0827\t0.283311\t0.031336\n",
      "4 \t -11592.025886143563 \t0.0092\t0.168930\t0.000924\n",
      "5 \t -11591.071668088716 \t0.0017\t0.054112\t0.000082\n",
      "6 \t -11590.797826513093 \t0.0005\t0.020210\t0.000024\n",
      "7 \t -11590.688835593966 \t0.0002\t0.009198\t0.000009\n",
      "Class marginals\n",
      "[0.33 0.33 0.33]\n",
      "Patient classes\n",
      "1 [0. 0. 1.]\n",
      "2 [1. 0. 0.]\n",
      "3 [0. 1. 0.]\n",
      "4 [0. 1. 0.]\n",
      "5 [0. 0. 1.]\n",
      "6 [0. 0. 1.]\n",
      "7 [0. 0. 1.]\n",
      "8 [1. 0. 0.]\n",
      "9 [1. 0. 0.]\n",
      "10 [1. 0. 0.]\n",
      "ACC MV on train: 0.7552356020942408\n",
      "ACC D&S on train: 0.9917102966841187\n",
      "Trained model over soft-MV\n",
      "Trained model over hard-MV\n",
      "Trained model over D&S\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Initializing new EM...\n",
      "Betas shape:  (100, 3, 3)\n",
      "Q estimate shape:  (2292, 3)\n",
      "Iter 1/50 \n",
      "M step: done,  E step: done //  (in 1.00 sec)\tlogL: -15538.208\t\n",
      "Iter 2/50 \n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -12057.743\tTol1: 0.22399\tTol2: 0.40707\t\n",
      "Iter 3/50 \n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -11671.377\tTol1: 0.03204\tTol2: 0.12474\t\n",
      "Iter 4/50 \n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -11539.248\tTol1: 0.01132\tTol2: 0.01321\t\n",
      "Iter 5/50 \n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -11422.426\tTol1: 0.01012\tTol2: 0.00189\t\n",
      "Iter 6/50 \n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -11310.094\tTol1: 0.00983\tTol2: 0.00078\t\n",
      "Finished training!\n",
      "Trained model over Raykar\n",
      "vector of repeats:\n",
      " [[ 2  0  9]\n",
      " [ 9  0  6]\n",
      " [ 4  2  2]\n",
      " ...\n",
      " [ 8  0  1]\n",
      " [ 2  5  0]\n",
      " [ 0  1 12]]\n",
      "shape: (2292, 3)\n",
      "Bayesian gaussian mixture say is 6 clusters \n",
      "DBSCAN say is 1 clusters\n",
      "Affinity Propagation say is 3 clusters\n",
      "Annotators PCA of annotations shape:  (100, 4)\n",
      "Normalized entropy (0-1) of repeats annotations: 0.5157111796212064\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [1. 1. 1.]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.05 sec)\tlogL: -22274.651\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.09 sec)\tlogL: -22182.359\tTol1: 0.00414\tTol2: 0.07794\tTol3: 0.00301\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -22062.149\tTol1: 0.00542\tTol2: 0.07465\tTol3: 0.00327\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21892.630\tTol1: 0.00768\tTol2: 0.07641\tTol3: 0.00370\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21657.763\tTol1: 0.01073\tTol2: 0.08144\tTol3: 0.00407\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21348.838\tTol1: 0.01426\tTol2: 0.08853\tTol3: 0.00459\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20968.143\tTol1: 0.01783\tTol2: 0.09572\tTol3: 0.00490\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20539.356\tTol1: 0.02045\tTol2: 0.10632\tTol3: 0.00505\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20089.562\tTol1: 0.02190\tTol2: 0.11615\tTol3: 0.00548\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19636.494\tTol1: 0.02255\tTol2: 0.12317\tTol3: 0.00569\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19189.246\tTol1: 0.02278\tTol2: 0.13060\tTol3: 0.00574\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18759.470\tTol1: 0.02240\tTol2: 0.13645\tTol3: 0.00610\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18382.809\tTol1: 0.02008\tTol2: 0.14071\tTol3: 0.00629\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18061.573\tTol1: 0.01747\tTol2: 0.13936\tTol3: 0.00494\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17806.087\tTol1: 0.01415\tTol2: 0.12832\tTol3: 0.00503\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17610.366\tTol1: 0.01099\tTol2: 0.11217\tTol3: 0.00417\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17452.619\tTol1: 0.00896\tTol2: 0.09064\tTol3: 0.00323\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17325.842\tTol1: 0.00726\tTol2: 0.06351\tTol3: 0.00263\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17219.599\tTol1: 0.00613\tTol2: 0.04437\tTol3: 0.00157\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17144.302\tTol1: 0.00437\tTol2: 0.02601\tTol3: 0.00177\t\n",
      "Iter 21/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17083.693\tTol1: 0.00354\tTol2: 0.01603\tTol3: 0.00211\t\n",
      "Finished training!\n",
      "Trained model over Ours (1)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.817  0.9505 0.4074]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.07 sec)\tlogL: -21797.295\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.09 sec)\tlogL: -21529.848\tTol1: 0.01227\tTol2: 0.07639\tTol3: 0.00400\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21256.578\tTol1: 0.01269\tTol2: 0.07934\tTol3: 0.01091\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20948.755\tTol1: 0.01448\tTol2: 0.08929\tTol3: 0.01352\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20596.781\tTol1: 0.01680\tTol2: 0.10332\tTol3: 0.01485\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20209.296\tTol1: 0.01881\tTol2: 0.11710\tTol3: 0.01521\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19798.712\tTol1: 0.02032\tTol2: 0.12710\tTol3: 0.01485\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19380.004\tTol1: 0.02115\tTol2: 0.13318\tTol3: 0.01330\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18988.503\tTol1: 0.02020\tTol2: 0.13226\tTol3: 0.01183\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18628.748\tTol1: 0.01895\tTol2: 0.12477\tTol3: 0.01011\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18308.892\tTol1: 0.01717\tTol2: 0.11376\tTol3: 0.00920\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18035.734\tTol1: 0.01492\tTol2: 0.10039\tTol3: 0.00803\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17803.811\tTol1: 0.01286\tTol2: 0.08481\tTol3: 0.00662\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17616.378\tTol1: 0.01053\tTol2: 0.06835\tTol3: 0.00608\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17464.330\tTol1: 0.00863\tTol2: 0.05540\tTol3: 0.00546\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17333.586\tTol1: 0.00749\tTol2: 0.04470\tTol3: 0.00451\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17234.919\tTol1: 0.00569\tTol2: 0.03688\tTol3: 0.00454\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17156.164\tTol1: 0.00457\tTol2: 0.03064\tTol3: 0.00426\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17093.176\tTol1: 0.00367\tTol2: 0.02606\tTol3: 0.00377\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17045.009\tTol1: 0.00282\tTol2: 0.02067\tTol3: 0.00333\t\n",
      "Iter 21/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17001.858\tTol1: 0.00253\tTol2: 0.01748\tTol3: 0.00307\t\n",
      "Finished training!\n",
      "Trained model over Ours (2)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.2317 0.6304 0.0053]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.12 sec)\tlogL: -20497.323\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -19944.742\tTol1: 0.02696\tTol2: 0.13643\tTol3: 0.00921\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19528.039\tTol1: 0.02089\tTol2: 0.08831\tTol3: 0.00621\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19178.335\tTol1: 0.01791\tTol2: 0.08081\tTol3: 0.00448\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18871.593\tTol1: 0.01599\tTol2: 0.08247\tTol3: 0.00411\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18606.553\tTol1: 0.01404\tTol2: 0.08339\tTol3: 0.00347\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18382.915\tTol1: 0.01202\tTol2: 0.08080\tTol3: 0.00296\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18190.171\tTol1: 0.01048\tTol2: 0.07559\tTol3: 0.00284\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18031.046\tTol1: 0.00875\tTol2: 0.06723\tTol3: 0.00297\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17885.520\tTol1: 0.00807\tTol2: 0.05775\tTol3: 0.00254\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17754.245\tTol1: 0.00734\tTol2: 0.04779\tTol3: 0.00260\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17642.041\tTol1: 0.00632\tTol2: 0.03789\tTol3: 0.00285\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17538.874\tTol1: 0.00585\tTol2: 0.03172\tTol3: 0.00278\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17446.994\tTol1: 0.00524\tTol2: 0.02710\tTol3: 0.00280\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17362.014\tTol1: 0.00487\tTol2: 0.02279\tTol3: 0.00331\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17286.228\tTol1: 0.00437\tTol2: 0.02292\tTol3: 0.00314\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17219.348\tTol1: 0.00387\tTol2: 0.01845\tTol3: 0.00339\t\n",
      "Finished training!\n",
      "Trained model over Ours (3)\n",
      " 32/765 [>.............................] - ETA: 0sAll Performance Measured\n",
      "New Synthetic data is being generated...Done! \n",
      "Shape (data,annotators):  (2292, 100)\n",
      "Classes:  3\n",
      "num Patients: 2292\n",
      "Iter\tlog-likelihood\tdelta-CM\tdelta-ER\tdelta-LL\n",
      "1 \t -15202.883425112772\n",
      "2 \t -12167.15299530936 \t0.4991\t0.382402\t0.199681\n",
      "3 \t -11852.922567520232 \t0.0715\t0.299090\t0.025826\n",
      "4 \t -11837.797841247808 \t0.0091\t0.177419\t0.001276\n",
      "5 \t -11834.74229313882 \t0.0028\t0.066123\t0.000258\n",
      "6 \t -11833.395406906868 \t0.0012\t0.024464\t0.000114\n",
      "7 \t -11832.683188398702 \t0.0006\t0.016505\t0.000060\n",
      "8 \t -11832.267941420681 \t0.0003\t0.011334\t0.000035\n",
      "9 \t -11831.753693569946 \t0.0002\t0.008118\t0.000043\n",
      "Class marginals\n",
      "[0.33 0.33 0.34]\n",
      "Patient classes\n",
      "1 [0.1402 0.     0.8598]\n",
      "2 [1. 0. 0.]\n",
      "3 [0. 1. 0.]\n",
      "4 [0. 1. 0.]\n",
      "5 [0. 0. 1.]\n",
      "6 [0.0001 0.     0.9999]\n",
      "7 [0. 0. 1.]\n",
      "8 [1. 0. 0.]\n",
      "9 [1. 0. 0.]\n",
      "10 [1. 0. 0.]\n",
      "ACC MV on train: 0.7897033158813264\n",
      "ACC D&S on train: 0.9930191972076788\n",
      "Trained model over soft-MV\n",
      "Trained model over hard-MV\n",
      "Trained model over D&S\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Initializing new EM...\n",
      "Betas shape:  (100, 3, 3)\n",
      "Q estimate shape:  (2292, 3)\n",
      "Iter 1/50 \n",
      "M step: done,  E step: done //  (in 1.19 sec)\tlogL: -15759.744\t\n",
      "Iter 2/50 \n",
      "M step: done,  E step: done //  (in 0.07 sec)\tlogL: -12764.744\tTol1: 0.19004\tTol2: 0.37890\t\n",
      "Iter 3/50 \n",
      "M step: done,  E step: done //  (in 0.07 sec)\tlogL: -12352.056\tTol1: 0.03233\tTol2: 0.13874\t\n",
      "Iter 4/50 \n",
      "M step: done,  E step: done //  (in 0.07 sec)\tlogL: -12205.443\tTol1: 0.01187\tTol2: 0.02215\t\n",
      "Iter 5/50 \n",
      "M step: done,  E step: done //  (in 0.07 sec)\tlogL: -12080.529\tTol1: 0.01023\tTol2: 0.00539\t\n",
      "Iter 6/50 \n",
      "M step: done,  E step: done //  (in 0.07 sec)\tlogL: -11962.287\tTol1: 0.00979\tTol2: 0.00243\t\n",
      "Finished training!\n",
      "Trained model over Raykar\n",
      "vector of repeats:\n",
      " [[ 0  0  3]\n",
      " [ 8  0  8]\n",
      " [ 5  5  2]\n",
      " ...\n",
      " [ 6  0  4]\n",
      " [ 7  2  2]\n",
      " [ 0  0 10]]\n",
      "shape: (2292, 3)\n",
      "Bayesian gaussian mixture say is 9 clusters \n",
      "DBSCAN say is 2 clusters\n",
      "Affinity Propagation say is 2 clusters\n",
      "Annotators PCA of annotations shape:  (100, 4)\n",
      "Normalized entropy (0-1) of repeats annotations: 0.5007779002426401\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [1. 1. 1.]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.20 sec)\tlogL: -21982.003\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -21845.791\tTol1: 0.00620\tTol2: 0.09426\tTol3: 0.00054\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21691.877\tTol1: 0.00705\tTol2: 0.08295\tTol3: 0.00101\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21506.841\tTol1: 0.00853\tTol2: 0.08006\tTol3: 0.00155\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21291.670\tTol1: 0.01000\tTol2: 0.08246\tTol3: 0.00214\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21038.963\tTol1: 0.01187\tTol2: 0.08842\tTol3: 0.00235\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20748.920\tTol1: 0.01379\tTol2: 0.09708\tTol3: 0.00287\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20419.523\tTol1: 0.01588\tTol2: 0.11090\tTol3: 0.00304\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20034.574\tTol1: 0.01885\tTol2: 0.12378\tTol3: 0.00366\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19592.647\tTol1: 0.02206\tTol2: 0.13300\tTol3: 0.00427\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19108.984\tTol1: 0.02469\tTol2: 0.13659\tTol3: 0.00488\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18596.580\tTol1: 0.02681\tTol2: 0.13291\tTol3: 0.00564\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18104.855\tTol1: 0.02644\tTol2: 0.12837\tTol3: 0.00669\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17670.587\tTol1: 0.02399\tTol2: 0.12238\tTol3: 0.00698\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17311.257\tTol1: 0.02033\tTol2: 0.11529\tTol3: 0.00673\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17029.547\tTol1: 0.01627\tTol2: 0.10386\tTol3: 0.00566\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16826.386\tTol1: 0.01193\tTol2: 0.08972\tTol3: 0.00504\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16681.129\tTol1: 0.00863\tTol2: 0.07394\tTol3: 0.00459\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16578.219\tTol1: 0.00617\tTol2: 0.05789\tTol3: 0.00402\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16490.877\tTol1: 0.00527\tTol2: 0.04276\tTol3: 0.00349\t\n",
      "Iter 21/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16437.861\tTol1: 0.00321\tTol2: 0.02795\tTol3: 0.00240\t\n",
      "Iter 22/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16391.123\tTol1: 0.00284\tTol2: 0.02133\tTol3: 0.00293\t\n",
      "Iter 23/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16350.265\tTol1: 0.00249\tTol2: 0.01798\tTol3: 0.00282\t\n",
      "Finished training!\n",
      "Trained model over Ours (1)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.7137 0.8711 0.8767]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.23 sec)\tlogL: -20108.144\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -19277.127\tTol1: 0.04133\tTol2: 0.20465\tTol3: 0.02096\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18511.328\tTol1: 0.03973\tTol2: 0.19708\tTol3: 0.01896\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17878.196\tTol1: 0.03420\tTol2: 0.19019\tTol3: 0.01575\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17406.719\tTol1: 0.02637\tTol2: 0.17820\tTol3: 0.01295\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17074.532\tTol1: 0.01908\tTol2: 0.16251\tTol3: 0.01040\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16843.634\tTol1: 0.01352\tTol2: 0.14322\tTol3: 0.00831\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16673.933\tTol1: 0.01008\tTol2: 0.11937\tTol3: 0.00603\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16553.935\tTol1: 0.00720\tTol2: 0.09265\tTol3: 0.00465\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16460.922\tTol1: 0.00562\tTol2: 0.06709\tTol3: 0.00396\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16387.554\tTol1: 0.00446\tTol2: 0.04700\tTol3: 0.00325\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16327.849\tTol1: 0.00364\tTol2: 0.03767\tTol3: 0.00263\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16277.533\tTol1: 0.00308\tTol2: 0.03146\tTol3: 0.00338\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16234.753\tTol1: 0.00263\tTol2: 0.02523\tTol3: 0.00291\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16199.873\tTol1: 0.00215\tTol2: 0.02429\tTol3: 0.00257\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16165.915\tTol1: 0.00210\tTol2: 0.02236\tTol3: 0.00270\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16140.538\tTol1: 0.00157\tTol2: 0.01826\tTol3: 0.00219\t\n",
      "Finished training!\n",
      "Trained model over Ours (2)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.3494 0.2281 0.4873]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.28 sec)\tlogL: -21130.162\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -20724.275\tTol1: 0.01921\tTol2: 0.08692\tTol3: 0.01734\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20327.739\tTol1: 0.01913\tTol2: 0.07888\tTol3: 0.00526\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19949.195\tTol1: 0.01862\tTol2: 0.09719\tTol3: 0.00610\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19586.577\tTol1: 0.01818\tTol2: 0.10879\tTol3: 0.00590\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19266.227\tTol1: 0.01636\tTol2: 0.11693\tTol3: 0.00596\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -18980.563\tTol1: 0.01483\tTol2: 0.11817\tTol3: 0.00529\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18724.810\tTol1: 0.01347\tTol2: 0.11525\tTol3: 0.00498\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18496.870\tTol1: 0.01217\tTol2: 0.10902\tTol3: 0.00488\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18297.992\tTol1: 0.01075\tTol2: 0.09785\tTol3: 0.00428\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18114.254\tTol1: 0.01004\tTol2: 0.08323\tTol3: 0.00364\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17947.916\tTol1: 0.00918\tTol2: 0.07153\tTol3: 0.00363\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17795.106\tTol1: 0.00851\tTol2: 0.05591\tTol3: 0.00266\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17647.678\tTol1: 0.00828\tTol2: 0.04951\tTol3: 0.00236\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17507.541\tTol1: 0.00794\tTol2: 0.04528\tTol3: 0.00221\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17384.428\tTol1: 0.00703\tTol2: 0.03865\tTol3: 0.00151\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17268.795\tTol1: 0.00665\tTol2: 0.03542\tTol3: 0.00122\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17168.111\tTol1: 0.00583\tTol2: 0.03142\tTol3: 0.00115\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17072.763\tTol1: 0.00555\tTol2: 0.02847\tTol3: 0.00091\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16985.965\tTol1: 0.00508\tTol2: 0.02485\tTol3: 0.00053\t\n",
      "Iter 21/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16915.198\tTol1: 0.00417\tTol2: 0.02448\tTol3: 0.00091\t\n",
      "Iter 22/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16846.790\tTol1: 0.00404\tTol2: 0.01899\tTol3: 0.00014\t\n",
      "Finished training!\n",
      "Trained model over Ours (3)\n",
      " 32/765 [>.............................] - ETA: 0sAll Performance Measured\n",
      "New Synthetic data is being generated...Done! \n",
      "Shape (data,annotators):  (2292, 100)\n",
      "Classes:  3\n",
      "num Patients: 2292\n",
      "Iter\tlog-likelihood\tdelta-CM\tdelta-ER\tdelta-LL\n",
      "1 \t -15428.821670015737\n",
      "2 \t -12341.901822545826 \t0.5428\t0.376246\t0.200075\n",
      "3 \t -11983.93001125878 \t0.0826\t0.271289\t0.029005\n",
      "4 \t -11969.116652327992 \t0.0107\t0.173861\t0.001236\n",
      "5 \t -11966.783617890222 \t0.0022\t0.065159\t0.000195\n",
      "6 \t -11966.600384830772 \t0.0004\t0.030148\t0.000015\n",
      "7 \t -11966.562109424458 \t0.0001\t0.016314\t0.000003\n",
      "8 \t -11966.548240583279 \t0.0001\t0.009747\t0.000001\n",
      "Class marginals\n",
      "[0.33 0.33 0.34]\n",
      "Patient classes\n",
      "1 [0. 0. 1.]\n",
      "2 [1. 0. 0.]\n",
      "3 [0.0009 0.0475 0.9516]\n",
      "4 [0. 1. 0.]\n",
      "5 [0. 0. 1.]\n",
      "6 [0.0006 0.     0.9994]\n",
      "7 [0. 0. 1.]\n",
      "8 [1. 0. 0.]\n",
      "9 [1. 0. 0.]\n",
      "10 [0.9991 0.0009 0.    ]\n",
      "ACC MV on train: 0.7617801047120419\n",
      "ACC D&S on train: 0.9947643979057592\n",
      "Trained model over soft-MV\n",
      "Trained model over hard-MV\n",
      "Trained model over D&S\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Initializing new EM...\n",
      "Betas shape:  (100, 3, 3)\n",
      "Q estimate shape:  (2292, 3)\n",
      "Iter 1/50 \n",
      "M step: done,  E step: done //  (in 1.29 sec)\tlogL: -15472.746\t\n",
      "Iter 2/50 \n",
      "M step: done,  E step: done //  (in 0.09 sec)\tlogL: -12338.808\tTol1: 0.20255\tTol2: 0.39009\t\n",
      "Iter 3/50 \n",
      "M step: done,  E step: done //  (in 0.12 sec)\tlogL: -11964.818\tTol1: 0.03031\tTol2: 0.12781\t\n",
      "Iter 4/50 \n",
      "M step: done,  E step: done //  (in 0.12 sec)\tlogL: -11838.875\tTol1: 0.01053\tTol2: 0.01255\t\n",
      "Iter 5/50 \n",
      "M step: done,  E step: done //  (in 0.12 sec)\tlogL: -11728.982\tTol1: 0.00928\tTol2: 0.00224\t\n",
      "Finished training!\n",
      "Trained model over Raykar\n",
      "vector of repeats:\n",
      " [[ 0  0 11]\n",
      " [ 7  0  1]\n",
      " [ 0  0  4]\n",
      " ...\n",
      " [ 6  0  4]\n",
      " [ 5  1  5]\n",
      " [ 0  0  7]]\n",
      "shape: (2292, 3)\n",
      "Bayesian gaussian mixture say is 8 clusters \n",
      "DBSCAN say is 1 clusters\n",
      "Affinity Propagation say is 3 clusters\n",
      "Annotators PCA of annotations shape:  (100, 4)\n",
      "Normalized entropy (0-1) of repeats annotations: 0.5057341282603321\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [1. 1. 1.]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.37 sec)\tlogL: -20980.249\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.09 sec)\tlogL: -20269.150\tTol1: 0.03389\tTol2: 0.18715\tTol3: 0.00830\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19708.135\tTol1: 0.02768\tTol2: 0.15588\tTol3: 0.00693\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19301.028\tTol1: 0.02066\tTol2: 0.13171\tTol3: 0.00537\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19032.169\tTol1: 0.01393\tTol2: 0.10795\tTol3: 0.00399\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18866.104\tTol1: 0.00873\tTol2: 0.08723\tTol3: 0.00266\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18759.759\tTol1: 0.00564\tTol2: 0.06988\tTol3: 0.00205\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18683.909\tTol1: 0.00404\tTol2: 0.05727\tTol3: 0.00122\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -18621.432\tTol1: 0.00334\tTol2: 0.04940\tTol3: 0.00110\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -18565.754\tTol1: 0.00299\tTol2: 0.04372\tTol3: 0.00102\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18509.272\tTol1: 0.00304\tTol2: 0.03950\tTol3: 0.00108\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18449.447\tTol1: 0.00323\tTol2: 0.03892\tTol3: 0.00103\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -18380.908\tTol1: 0.00371\tTol2: 0.03985\tTol3: 0.00111\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18306.348\tTol1: 0.00406\tTol2: 0.04155\tTol3: 0.00108\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18232.952\tTol1: 0.00401\tTol2: 0.04347\tTol3: 0.00123\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18157.837\tTol1: 0.00412\tTol2: 0.04528\tTol3: 0.00141\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -18080.591\tTol1: 0.00425\tTol2: 0.04648\tTol3: 0.00153\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -18005.265\tTol1: 0.00417\tTol2: 0.04952\tTol3: 0.00137\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17931.527\tTol1: 0.00410\tTol2: 0.04854\tTol3: 0.00132\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17851.005\tTol1: 0.00449\tTol2: 0.04826\tTol3: 0.00139\t\n",
      "Iter 21/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17782.665\tTol1: 0.00383\tTol2: 0.04795\tTol3: 0.00129\t\n",
      "Iter 22/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17716.968\tTol1: 0.00369\tTol2: 0.04562\tTol3: 0.00146\t\n",
      "Iter 23/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17645.674\tTol1: 0.00402\tTol2: 0.04368\tTol3: 0.00143\t\n",
      "Iter 24/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17577.714\tTol1: 0.00385\tTol2: 0.04232\tTol3: 0.00159\t\n",
      "Iter 25/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17500.039\tTol1: 0.00442\tTol2: 0.03823\tTol3: 0.00192\t\n",
      "Iter 26/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17422.884\tTol1: 0.00441\tTol2: 0.03509\tTol3: 0.00168\t\n",
      "Iter 27/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17342.336\tTol1: 0.00462\tTol2: 0.03227\tTol3: 0.00193\t\n",
      "Iter 28/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17258.945\tTol1: 0.00481\tTol2: 0.02825\tTol3: 0.00216\t\n",
      "Iter 29/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17175.255\tTol1: 0.00485\tTol2: 0.02461\tTol3: 0.00268\t\n",
      "Iter 30/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17086.170\tTol1: 0.00519\tTol2: 0.02422\tTol3: 0.00280\t\n",
      "Iter 31/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16998.273\tTol1: 0.00514\tTol2: 0.02215\tTol3: 0.00280\t\n",
      "Iter 32/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16915.958\tTol1: 0.00484\tTol2: 0.01939\tTol3: 0.00240\t\n",
      "Finished training!\n",
      "Trained model over Ours (1)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.2618 0.7823 0.0237]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.39 sec)\tlogL: -21147.009\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -20731.164\tTol1: 0.01966\tTol2: 0.13991\tTol3: 0.02317\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20308.605\tTol1: 0.02038\tTol2: 0.10447\tTol3: 0.02260\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19860.474\tTol1: 0.02207\tTol2: 0.09261\tTol3: 0.02284\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19420.860\tTol1: 0.02214\tTol2: 0.08743\tTol3: 0.02160\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18993.563\tTol1: 0.02200\tTol2: 0.08946\tTol3: 0.01941\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18604.088\tTol1: 0.02051\tTol2: 0.09138\tTol3: 0.01720\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18254.005\tTol1: 0.01882\tTol2: 0.09279\tTol3: 0.01477\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17952.785\tTol1: 0.01650\tTol2: 0.09044\tTol3: 0.01185\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17697.958\tTol1: 0.01419\tTol2: 0.08347\tTol3: 0.00911\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17488.659\tTol1: 0.01183\tTol2: 0.07482\tTol3: 0.00640\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17328.120\tTol1: 0.00918\tTol2: 0.06659\tTol3: 0.00413\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17204.210\tTol1: 0.00715\tTol2: 0.06012\tTol3: 0.00263\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17111.534\tTol1: 0.00539\tTol2: 0.05275\tTol3: 0.00157\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17030.135\tTol1: 0.00476\tTol2: 0.04555\tTol3: 0.00088\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16966.711\tTol1: 0.00372\tTol2: 0.04144\tTol3: 0.00083\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16908.964\tTol1: 0.00340\tTol2: 0.03288\tTol3: 0.00070\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16866.872\tTol1: 0.00249\tTol2: 0.02711\tTol3: 0.00055\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16832.083\tTol1: 0.00206\tTol2: 0.02135\tTol3: 0.00056\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16796.899\tTol1: 0.00209\tTol2: 0.01749\tTol3: 0.00051\t\n",
      "Finished training!\n",
      "Trained model over Ours (2)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.4188 0.3226 0.9598]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.43 sec)\tlogL: -21243.703\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -20954.674\tTol1: 0.01361\tTol2: 0.08141\tTol3: 0.01037\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20681.102\tTol1: 0.01306\tTol2: 0.06499\tTol3: 0.00120\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20401.621\tTol1: 0.01351\tTol2: 0.07216\tTol3: 0.00504\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20120.437\tTol1: 0.01378\tTol2: 0.08733\tTol3: 0.00710\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19830.478\tTol1: 0.01441\tTol2: 0.10008\tTol3: 0.00916\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19533.521\tTol1: 0.01497\tTol2: 0.11140\tTol3: 0.01067\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19229.345\tTol1: 0.01557\tTol2: 0.12056\tTol3: 0.01224\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18925.764\tTol1: 0.01579\tTol2: 0.12728\tTol3: 0.01389\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18622.594\tTol1: 0.01602\tTol2: 0.13100\tTol3: 0.01431\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18330.657\tTol1: 0.01568\tTol2: 0.13356\tTol3: 0.01562\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18059.895\tTol1: 0.01477\tTol2: 0.13177\tTol3: 0.01659\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17811.591\tTol1: 0.01375\tTol2: 0.12567\tTol3: 0.01680\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17586.898\tTol1: 0.01261\tTol2: 0.11539\tTol3: 0.01697\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17382.643\tTol1: 0.01161\tTol2: 0.10293\tTol3: 0.01703\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17197.528\tTol1: 0.01065\tTol2: 0.09004\tTol3: 0.01591\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17034.759\tTol1: 0.00946\tTol2: 0.07544\tTol3: 0.01551\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16895.202\tTol1: 0.00819\tTol2: 0.06358\tTol3: 0.01431\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16776.293\tTol1: 0.00704\tTol2: 0.05475\tTol3: 0.01307\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16671.730\tTol1: 0.00623\tTol2: 0.04719\tTol3: 0.01186\t\n",
      "Iter 21/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16583.918\tTol1: 0.00527\tTol2: 0.03962\tTol3: 0.01055\t\n",
      "Iter 22/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16514.544\tTol1: 0.00418\tTol2: 0.03474\tTol3: 0.00842\t\n",
      "Iter 23/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16458.654\tTol1: 0.00338\tTol2: 0.03228\tTol3: 0.00722\t\n",
      "Iter 24/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16403.274\tTol1: 0.00336\tTol2: 0.02935\tTol3: 0.00647\t\n",
      "Iter 25/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16359.105\tTol1: 0.00269\tTol2: 0.02882\tTol3: 0.00577\t\n",
      "Iter 26/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16319.477\tTol1: 0.00242\tTol2: 0.02765\tTol3: 0.00502\t\n",
      "Iter 27/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16290.617\tTol1: 0.00177\tTol2: 0.02538\tTol3: 0.00394\t\n",
      "Iter 28/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16260.883\tTol1: 0.00183\tTol2: 0.02645\tTol3: 0.00378\t\n",
      "Iter 29/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16233.525\tTol1: 0.00168\tTol2: 0.02696\tTol3: 0.00339\t\n",
      "Iter 30/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16209.269\tTol1: 0.00149\tTol2: 0.02961\tTol3: 0.00331\t\n",
      "Iter 31/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16183.841\tTol1: 0.00157\tTol2: 0.02695\tTol3: 0.00271\t\n",
      "Iter 32/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16160.861\tTol1: 0.00142\tTol2: 0.02708\tTol3: 0.00228\t\n",
      "Iter 33/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16140.381\tTol1: 0.00127\tTol2: 0.02799\tTol3: 0.00199\t\n",
      "Iter 34/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16121.436\tTol1: 0.00117\tTol2: 0.02926\tTol3: 0.00186\t\n",
      "Iter 35/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16107.687\tTol1: 0.00085\tTol2: 0.02845\tTol3: 0.00152\t\n",
      "Iter 36/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16093.681\tTol1: 0.00087\tTol2: 0.02787\tTol3: 0.00147\t\n",
      "Iter 37/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16078.475\tTol1: 0.00094\tTol2: 0.02721\tTol3: 0.00130\t\n",
      "Iter 38/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16069.002\tTol1: 0.00059\tTol2: 0.02380\tTol3: 0.00078\t\n",
      "Iter 39/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16061.282\tTol1: 0.00048\tTol2: 0.02340\tTol3: 0.00069\t\n",
      "Iter 40/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16043.062\tTol1: 0.00113\tTol2: 0.02283\tTol3: 0.00058\t\n",
      "Iter 41/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16031.671\tTol1: 0.00071\tTol2: 0.02016\tTol3: 0.00033\t\n",
      "Iter 42/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16019.743\tTol1: 0.00074\tTol2: 0.02141\tTol3: 0.00018\t\n",
      "Iter 43/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16008.557\tTol1: 0.00070\tTol2: 0.02107\tTol3: 0.00026\t\n",
      "Iter 44/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16002.740\tTol1: 0.00036\tTol2: 0.02174\tTol3: 0.00021\t\n",
      "Iter 45/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15996.152\tTol1: 0.00041\tTol2: 0.02086\tTol3: 0.00019\t\n",
      "Iter 46/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15991.190\tTol1: 0.00031\tTol2: 0.01976\tTol3: 0.00025\t\n",
      "Finished training!\n",
      "Trained model over Ours (3)\n",
      "2292/2292 [==============================] - 0s      \n",
      " 32/765 [>.............................] - ETA: 0sAll Performance Measured\n",
      "New Synthetic data is being generated...Done! \n",
      "Shape (data,annotators):  (2292, 100)\n",
      "Classes:  3\n",
      "num Patients: 2292\n",
      "Iter\tlog-likelihood\tdelta-CM\tdelta-ER\tdelta-LL\n",
      "1 \t -14742.043320062652\n",
      "2 \t -11783.458412595983 \t0.4146\t0.398726\t0.200690\n",
      "3 \t -11613.131811773355 \t0.0511\t0.264610\t0.014455\n",
      "4 \t -11609.821852208168 \t0.0043\t0.130096\t0.000285\n",
      "5 \t -11608.978073384338 \t0.0010\t0.038503\t0.000073\n",
      "6 \t -11608.689800994913 \t0.0003\t0.013142\t0.000025\n",
      "7 \t -11608.635625389361 \t0.0001\t0.009808\t0.000005\n",
      "Class marginals\n",
      "[0.33 0.33 0.34]\n",
      "Patient classes\n",
      "1 [0. 0. 1.]\n",
      "2 [1. 0. 0.]\n",
      "3 [0.     0.9997 0.0003]\n",
      "4 [0. 1. 0.]\n",
      "5 [0.0004 0.     0.9996]\n",
      "6 [0. 0. 1.]\n",
      "7 [0. 0. 1.]\n",
      "8 [1. 0. 0.]\n",
      "9 [1. 0. 0.]\n",
      "10 [1. 0. 0.]\n",
      "ACC MV on train: 0.8660558464223386\n",
      "ACC D&S on train: 0.9973821989528796\n",
      "Trained model over soft-MV\n",
      "Trained model over hard-MV\n",
      "Trained model over D&S\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Initializing new EM...\n",
      "Betas shape:  (100, 3, 3)\n",
      "Q estimate shape:  (2292, 3)\n",
      "Iter 1/50 \n",
      "M step: done,  E step: done //  (in 1.43 sec)\tlogL: -15431.850\t\n",
      "Iter 2/50 \n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -12366.768\tTol1: 0.19862\tTol2: 0.38990\t\n",
      "Iter 3/50 \n",
      "M step: done,  E step: done //  (in 0.09 sec)\tlogL: -12079.055\tTol1: 0.02327\tTol2: 0.08272\t\n",
      "Iter 4/50 \n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -11929.042\tTol1: 0.01242\tTol2: 0.00505\t\n",
      "Iter 5/50 \n",
      "M step: done,  E step: done //  (in 0.12 sec)\tlogL: -11800.334\tTol1: 0.01079\tTol2: 0.00106\t\n",
      "Iter 6/50 \n",
      "M step: done,  E step: done //  (in 0.12 sec)\tlogL: -11683.771\tTol1: 0.00988\tTol2: 0.00066\t\n",
      "Finished training!\n",
      "Trained model over Raykar\n",
      "vector of repeats:\n",
      " [[ 0  0 10]\n",
      " [ 4  0  3]\n",
      " [ 2  2  2]\n",
      " ...\n",
      " [ 8  0  3]\n",
      " [ 2  7  2]\n",
      " [ 0  0 10]]\n",
      "shape: (2292, 3)\n",
      "Bayesian gaussian mixture say is 5 clusters \n",
      "DBSCAN say is 1 clusters\n",
      "Affinity Propagation say is 3 clusters\n",
      "Annotators PCA of annotations shape:  (100, 4)\n",
      "Normalized entropy (0-1) of repeats annotations: 0.484750620111579\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [1. 1. 1.]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.50 sec)\tlogL: -22232.586\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.09 sec)\tlogL: -21728.946\tTol1: 0.02265\tTol2: 0.17629\tTol3: 0.01747\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -21209.902\tTol1: 0.02389\tTol2: 0.15633\tTol3: 0.01551\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20725.413\tTol1: 0.02284\tTol2: 0.14655\tTol3: 0.01331\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20317.018\tTol1: 0.01971\tTol2: 0.13754\tTol3: 0.01040\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19986.824\tTol1: 0.01625\tTol2: 0.13281\tTol3: 0.00776\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19709.129\tTol1: 0.01389\tTol2: 0.12822\tTol3: 0.00581\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19439.650\tTol1: 0.01367\tTol2: 0.12783\tTol3: 0.00463\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19148.619\tTol1: 0.01497\tTol2: 0.13035\tTol3: 0.00418\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18814.550\tTol1: 0.01745\tTol2: 0.13356\tTol3: 0.00474\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18449.038\tTol1: 0.01943\tTol2: 0.13466\tTol3: 0.00536\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18069.011\tTol1: 0.02060\tTol2: 0.13440\tTol3: 0.00677\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17685.581\tTol1: 0.02122\tTol2: 0.13171\tTol3: 0.00741\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17316.943\tTol1: 0.02084\tTol2: 0.12945\tTol3: 0.00781\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16970.415\tTol1: 0.02001\tTol2: 0.11858\tTol3: 0.00851\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16671.058\tTol1: 0.01764\tTol2: 0.10177\tTol3: 0.00845\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16417.170\tTol1: 0.01523\tTol2: 0.07791\tTol3: 0.00796\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16204.180\tTol1: 0.01297\tTol2: 0.05456\tTol3: 0.00704\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16040.637\tTol1: 0.01009\tTol2: 0.03844\tTol3: 0.00613\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15908.742\tTol1: 0.00822\tTol2: 0.02850\tTol3: 0.00483\t\n",
      "Iter 21/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15810.503\tTol1: 0.00618\tTol2: 0.02905\tTol3: 0.00425\t\n",
      "Iter 22/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15735.289\tTol1: 0.00476\tTol2: 0.03179\tTol3: 0.00380\t\n",
      "Iter 23/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15676.297\tTol1: 0.00375\tTol2: 0.03333\tTol3: 0.00388\t\n",
      "Iter 24/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15627.831\tTol1: 0.00309\tTol2: 0.03208\tTol3: 0.00344\t\n",
      "Iter 25/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15592.512\tTol1: 0.00226\tTol2: 0.03017\tTol3: 0.00270\t\n",
      "Iter 26/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15564.838\tTol1: 0.00177\tTol2: 0.02991\tTol3: 0.00246\t\n",
      "Iter 27/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15545.028\tTol1: 0.00127\tTol2: 0.03135\tTol3: 0.00276\t\n",
      "Iter 28/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15524.984\tTol1: 0.00129\tTol2: 0.03169\tTol3: 0.00322\t\n",
      "Iter 29/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15514.487\tTol1: 0.00068\tTol2: 0.02921\tTol3: 0.00306\t\n",
      "Iter 30/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15504.348\tTol1: 0.00065\tTol2: 0.02468\tTol3: 0.00226\t\n",
      "Iter 31/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15493.592\tTol1: 0.00069\tTol2: 0.02155\tTol3: 0.00196\t\n",
      "Iter 32/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15482.943\tTol1: 0.00069\tTol2: 0.02100\tTol3: 0.00211\t\n",
      "Iter 33/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15473.629\tTol1: 0.00060\tTol2: 0.01802\tTol3: 0.00173\t\n",
      "Finished training!\n",
      "Trained model over Ours (1)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.0268 0.3597 0.3716]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.59 sec)\tlogL: -22655.133\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -21837.346\tTol1: 0.03610\tTol2: 0.26725\tTol3: 0.05757\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -21468.712\tTol1: 0.01688\tTol2: 0.10976\tTol3: 0.02081\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -21153.645\tTol1: 0.01468\tTol2: 0.07257\tTol3: 0.00635\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20862.814\tTol1: 0.01375\tTol2: 0.06430\tTol3: 0.00228\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20590.108\tTol1: 0.01307\tTol2: 0.06073\tTol3: 0.00074\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20332.913\tTol1: 0.01249\tTol2: 0.05924\tTol3: 0.00069\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20090.216\tTol1: 0.01194\tTol2: 0.05623\tTol3: 0.00064\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19861.123\tTol1: 0.01140\tTol2: 0.05276\tTol3: 0.00080\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19658.146\tTol1: 0.01022\tTol2: 0.04865\tTol3: 0.00111\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19460.179\tTol1: 0.01007\tTol2: 0.04365\tTol3: 0.00141\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19278.189\tTol1: 0.00935\tTol2: 0.04012\tTol3: 0.00171\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19110.258\tTol1: 0.00871\tTol2: 0.03706\tTol3: 0.00153\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18959.248\tTol1: 0.00790\tTol2: 0.03362\tTol3: 0.00084\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18821.618\tTol1: 0.00726\tTol2: 0.02878\tTol3: 0.00136\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18694.688\tTol1: 0.00674\tTol2: 0.02455\tTol3: 0.00123\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18569.729\tTol1: 0.00668\tTol2: 0.02071\tTol3: 0.00101\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18453.906\tTol1: 0.00624\tTol2: 0.01709\tTol3: 0.00122\t\n",
      "Finished training!\n",
      "Trained model over Ours (2)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.3977 0.4662 0.4046]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.57 sec)\tlogL: -21680.614\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21226.877\tTol1: 0.02093\tTol2: 0.10204\tTol3: 0.01272\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20785.867\tTol1: 0.02078\tTol2: 0.10335\tTol3: 0.00632\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20323.135\tTol1: 0.02226\tTol2: 0.12328\tTol3: 0.00562\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19851.419\tTol1: 0.02321\tTol2: 0.13861\tTol3: 0.00690\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19404.321\tTol1: 0.02252\tTol2: 0.14876\tTol3: 0.00743\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18999.048\tTol1: 0.02089\tTol2: 0.15226\tTol3: 0.00743\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18651.383\tTol1: 0.01830\tTol2: 0.14911\tTol3: 0.00658\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -18346.311\tTol1: 0.01636\tTol2: 0.13974\tTol3: 0.00572\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18069.862\tTol1: 0.01507\tTol2: 0.12571\tTol3: 0.00593\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17811.690\tTol1: 0.01429\tTol2: 0.10778\tTol3: 0.00502\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17574.754\tTol1: 0.01330\tTol2: 0.08734\tTol3: 0.00474\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17363.314\tTol1: 0.01203\tTol2: 0.06707\tTol3: 0.00448\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17162.043\tTol1: 0.01159\tTol2: 0.04962\tTol3: 0.00498\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16990.831\tTol1: 0.00998\tTol2: 0.03485\tTol3: 0.00442\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16828.921\tTol1: 0.00953\tTol2: 0.02355\tTol3: 0.00412\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16688.482\tTol1: 0.00835\tTol2: 0.01621\tTol3: 0.00425\t\n",
      "Finished training!\n",
      "Trained model over Ours (3)\n",
      "2292/2292 [==============================] - 0s      \n",
      " 32/765 [>.............................] - ETA: 0sAll Performance Measured\n",
      "New Synthetic data is being generated...Done! \n",
      "Shape (data,annotators):  (2292, 100)\n",
      "Classes:  3\n",
      "num Patients: 2292\n",
      "Iter\tlog-likelihood\tdelta-CM\tdelta-ER\tdelta-LL\n",
      "1 \t -14998.444306714875\n",
      "2 \t -12384.604034346923 \t0.3929\t0.379960\t0.174274\n",
      "3 \t -12187.299440099625 \t0.0612\t0.276112\t0.015931\n",
      "4 \t -12180.663992046062 \t0.0065\t0.176423\t0.000544\n",
      "5 \t -12179.60744188328 \t0.0018\t0.062659\t0.000087\n",
      "6 \t -12179.235445296968 \t0.0007\t0.021877\t0.000031\n",
      "7 \t -12179.057940514507 \t0.0004\t0.010363\t0.000015\n",
      "8 \t -12178.96845393331 \t0.0002\t0.007176\t0.000007\n",
      "Class marginals\n",
      "[0.33 0.33 0.34]\n",
      "Patient classes\n",
      "1 [0.     0.0001 0.9999]\n",
      "2 [1. 0. 0.]\n",
      "3 [0. 1. 0.]\n",
      "4 [0. 1. 0.]\n",
      "5 [0.     0.0001 0.9999]\n",
      "6 [0. 0. 1.]\n",
      "7 [0.     0.0861 0.9139]\n",
      "8 [1. 0. 0.]\n",
      "9 [1. 0. 0.]\n",
      "10 [1. 0. 0.]\n",
      "ACC MV on train: 0.8778359511343804\n",
      "ACC D&S on train: 0.9960732984293194\n",
      "Trained model over soft-MV\n",
      "Trained model over hard-MV\n",
      "Trained model over D&S\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Initializing new EM...\n",
      "Betas shape:  (100, 3, 3)\n",
      "Q estimate shape:  (2292, 3)\n",
      "Iter 1/50 \n",
      "M step: done,  E step: done //  (in 1.58 sec)\tlogL: -14602.166\t\n",
      "Iter 2/50 \n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -11908.051\tTol1: 0.18450\tTol2: 0.37592\t\n",
      "Iter 3/50 \n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -11693.133\tTol1: 0.01805\tTol2: 0.08006\t\n",
      "Iter 4/50 \n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -11586.529\tTol1: 0.00912\tTol2: 0.00704\t\n",
      "Finished training!\n",
      "Trained model over Raykar\n",
      "vector of repeats:\n",
      " [[1 0 9]\n",
      " [7 0 2]\n",
      " [3 6 2]\n",
      " ...\n",
      " [8 0 2]\n",
      " [2 5 4]\n",
      " [0 0 7]]\n",
      "shape: (2292, 3)\n",
      "Bayesian gaussian mixture say is 5 clusters \n",
      "DBSCAN say is 1 clusters\n",
      "Affinity Propagation say is 3 clusters\n",
      "Annotators PCA of annotations shape:  (100, 4)\n",
      "Normalized entropy (0-1) of repeats annotations: 0.4680588405794959\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [1. 1. 1.]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.64 sec)\tlogL: -22459.643\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.09 sec)\tlogL: -22126.896\tTol1: 0.01482\tTol2: 0.12280\tTol3: 0.00801\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -21741.256\tTol1: 0.01743\tTol2: 0.10966\tTol3: 0.00764\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21284.422\tTol1: 0.02101\tTol2: 0.10768\tTol3: 0.00733\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20801.336\tTol1: 0.02270\tTol2: 0.10913\tTol3: 0.00687\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20355.240\tTol1: 0.02145\tTol2: 0.11092\tTol3: 0.00602\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19968.716\tTol1: 0.01899\tTol2: 0.11041\tTol3: 0.00498\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19633.736\tTol1: 0.01678\tTol2: 0.10801\tTol3: 0.00416\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19336.094\tTol1: 0.01516\tTol2: 0.10368\tTol3: 0.00357\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19045.096\tTol1: 0.01505\tTol2: 0.10171\tTol3: 0.00295\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -18724.594\tTol1: 0.01683\tTol2: 0.10313\tTol3: 0.00285\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18360.951\tTol1: 0.01942\tTol2: 0.10490\tTol3: 0.00323\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17964.877\tTol1: 0.02157\tTol2: 0.10686\tTol3: 0.00380\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17571.313\tTol1: 0.02191\tTol2: 0.11000\tTol3: 0.00401\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17211.103\tTol1: 0.02050\tTol2: 0.10831\tTol3: 0.00390\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16906.824\tTol1: 0.01768\tTol2: 0.10832\tTol3: 0.00357\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16672.466\tTol1: 0.01386\tTol2: 0.10636\tTol3: 0.00314\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16492.104\tTol1: 0.01082\tTol2: 0.10129\tTol3: 0.00337\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16349.362\tTol1: 0.00866\tTol2: 0.08844\tTol3: 0.00323\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16231.876\tTol1: 0.00719\tTol2: 0.07408\tTol3: 0.00331\t\n",
      "Iter 21/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16136.373\tTol1: 0.00588\tTol2: 0.05603\tTol3: 0.00274\t\n",
      "Iter 22/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16047.175\tTol1: 0.00553\tTol2: 0.04436\tTol3: 0.00313\t\n",
      "Iter 23/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15976.485\tTol1: 0.00441\tTol2: 0.03487\tTol3: 0.00281\t\n",
      "Iter 24/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15911.026\tTol1: 0.00410\tTol2: 0.02879\tTol3: 0.00291\t\n",
      "Iter 25/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15855.783\tTol1: 0.00347\tTol2: 0.02329\tTol3: 0.00259\t\n",
      "Iter 26/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15803.891\tTol1: 0.00327\tTol2: 0.02105\tTol3: 0.00263\t\n",
      "Iter 27/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15762.170\tTol1: 0.00264\tTol2: 0.01871\tTol3: 0.00242\t\n",
      "Finished training!\n",
      "Trained model over Ours (1)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.6398 0.0698 0.2368]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.67 sec)\tlogL: -18206.448\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.09 sec)\tlogL: -17557.771\tTol1: 0.03563\tTol2: 0.22805\tTol3: 0.04509\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17092.360\tTol1: 0.02651\tTol2: 0.18344\tTol3: 0.03187\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16772.418\tTol1: 0.01872\tTol2: 0.15375\tTol3: 0.02294\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16544.714\tTol1: 0.01358\tTol2: 0.13071\tTol3: 0.01684\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16381.550\tTol1: 0.00986\tTol2: 0.10885\tTol3: 0.01265\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16260.742\tTol1: 0.00737\tTol2: 0.08782\tTol3: 0.00940\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.12 sec)\tlogL: -16167.186\tTol1: 0.00575\tTol2: 0.07023\tTol3: 0.00749\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -16090.891\tTol1: 0.00472\tTol2: 0.05518\tTol3: 0.00600\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -16027.930\tTol1: 0.00391\tTol2: 0.04190\tTol3: 0.00491\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15969.284\tTol1: 0.00366\tTol2: 0.03263\tTol3: 0.00446\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15923.592\tTol1: 0.00286\tTol2: 0.02730\tTol3: 0.00405\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15883.646\tTol1: 0.00251\tTol2: 0.02492\tTol3: 0.00363\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15850.085\tTol1: 0.00211\tTol2: 0.02409\tTol3: 0.00344\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15820.600\tTol1: 0.00186\tTol2: 0.02220\tTol3: 0.00313\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15792.980\tTol1: 0.00175\tTol2: 0.02116\tTol3: 0.00286\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15767.954\tTol1: 0.00158\tTol2: 0.02026\tTol3: 0.00272\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15743.140\tTol1: 0.00157\tTol2: 0.02136\tTol3: 0.00278\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -15722.336\tTol1: 0.00132\tTol2: 0.02089\tTol3: 0.00252\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -15702.521\tTol1: 0.00126\tTol2: 0.01900\tTol3: 0.00235\t\n",
      "Finished training!\n",
      "Trained model over Ours (2)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.1809 0.048  0.8942]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2292, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2292, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 1.71 sec)\tlogL: -20743.865\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.09 sec)\tlogL: -20018.128\tTol1: 0.03499\tTol2: 0.26882\tTol3: 0.02022\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19571.890\tTol1: 0.02229\tTol2: 0.19296\tTol3: 0.00593\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19195.116\tTol1: 0.01925\tTol2: 0.15564\tTol3: 0.00608\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -18856.164\tTol1: 0.01766\tTol2: 0.13665\tTol3: 0.00597\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -18547.236\tTol1: 0.01638\tTol2: 0.12049\tTol3: 0.00527\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -18265.342\tTol1: 0.01520\tTol2: 0.10108\tTol3: 0.00429\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -18009.489\tTol1: 0.01401\tTol2: 0.07934\tTol3: 0.00391\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17778.648\tTol1: 0.01282\tTol2: 0.05953\tTol3: 0.00365\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17565.302\tTol1: 0.01200\tTol2: 0.04410\tTol3: 0.00319\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17365.555\tTol1: 0.01137\tTol2: 0.03246\tTol3: 0.00328\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -17179.151\tTol1: 0.01073\tTol2: 0.02405\tTol3: 0.00252\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -17013.023\tTol1: 0.00967\tTol2: 0.01794\tTol3: 0.00237\t\n",
      "Finished training!\n",
      "Trained model over Ours (3)\n",
      "2292/2292 [==============================] - 0s     \n",
      " 32/765 [>.............................] - ETA: 0sAll Performance Measured\n"
     ]
    }
   ],
   "source": [
    "folder = \"..\" #folder of where is syntetic folder --arg\n",
    "\n",
    "GenerateData = SinteticData()\n",
    "\n",
    "#CONFUSION MATRIX CHOOSE\n",
    "if scenario == 1 or scenario == 3 or scenario == 4 or scenario == 5 or scenario == 6:\n",
    "    GenerateData.set_probas(asfile=True,file_matrix=folder+'/syntetic/simple/matrix_datasim_normal.csv',file_groups =folder+'/syntetic/simple/groups_datasim.csv')\n",
    "\n",
    "elif scenario == 2 or scenario == 7: #bad MV\n",
    "    GenerateData.set_probas(asfile=True,file_matrix=folder+'/syntetic/simple/matrix_datasim_badMV.csv',file_groups =folder+'/syntetic/simple/groups_datasim.csv')\n",
    "\n",
    "real_conf_matrix = GenerateData.conf_matrix.copy()\n",
    "\n",
    "\n",
    "#ANNOTATOR DENSITY CHOOSE\n",
    "if scenario == 1 or scenario ==2 or scneario == 3:\n",
    "    Tmax = 100\n",
    "    T_data = 10 \n",
    "    \n",
    "elif scenario == 4 or scenario == 7:\n",
    "    Tmax = 2000\n",
    "    T_data = 20 \n",
    "    \n",
    "elif scenario == 5:\n",
    "    Tmax = 5000\n",
    "    T_data = 25\n",
    "\n",
    "elif scenario == 6:\n",
    "    Tmax = 10000\n",
    "    T_data = 40\n",
    "\n",
    "\n",
    "results_softmv_train = []\n",
    "results_softmv_test = []\n",
    "results_hardmv_train = []\n",
    "results_hardmv_test = []\n",
    "results_ds_train = []\n",
    "results_ds_test = []\n",
    "results_raykar_train = []\n",
    "results_raykar_trainA = []\n",
    "results_raykar_test = []\n",
    "results_ours1_train = []\n",
    "results_ours1_trainA = []\n",
    "results_ours1_test = []\n",
    "results_ours1_testA = []\n",
    "results_ours2_train = []\n",
    "results_ours2_trainA = []\n",
    "results_ours2_test = []\n",
    "results_ours2_testA = []\n",
    "results_ours3_train = []\n",
    "results_ours3_trainA = []\n",
    "results_ours3_test = []\n",
    "results_ours3_testA = []\n",
    "\n",
    "for _ in range(5): #repetitions\n",
    "    print(\"New Synthetic data is being generated...\",flush=True,end='')\n",
    "    if scenario == 3: #soft\n",
    "        y_obs, groups_annot = GenerateData.sintetic_annotate_data(Z_train,Tmax,T_data,deterministic=False,hard=False)\n",
    "    else:\n",
    "        y_obs, groups_annot = GenerateData.sintetic_annotate_data(Z_train,Tmax,T_data,deterministic=False)\n",
    "    print(\"Done! \")\n",
    "    \n",
    "    if len(groups_annot.shape) ==1 or groups_annot.shape[1] ==  1: \n",
    "        groups_annot = keras.utils.to_categorical(groups_annot)  #only if it is hard clustering\n",
    "    confe_matrix = np.tensordot(groups_annot,real_conf_matrix, axes=[[1],[0]])\n",
    "\n",
    "    N,T = y_obs.shape\n",
    "    K = np.max(y_obs)+1 # asumiendo que estan ordenadas\n",
    "    print(\"Shape (data,annotators): \",(N,T))\n",
    "    print(\"Classes: \",K)\n",
    "    \n",
    "    ############# EXECUTE ALGORITHMS #############################\n",
    "\n",
    "    label_I = LabelInference(y_obs,TOL,type_inf = 'all')  #Infer Labels\n",
    "\n",
    "    mv_onehot = label_I.mv_labels('onehot')\n",
    "    mv_probas = label_I.mv_labels('probas')\n",
    "\n",
    "    ds_labels = label_I.DS_labels()\n",
    "    \n",
    "    print(\"ACC MV on train:\",np.mean(mv_onehot.argmax(axis=1)==Z_train))\n",
    "    print(\"ACC D&S on train:\",np.mean(ds_labels.argmax(axis=1)==Z_train))\n",
    "        \n",
    "    model_mvsoft = clone_model(model_UB) \n",
    "    model_mvsoft.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "    model_mvsoft.fit(Xstd_train, mv_probas, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0)\n",
    "    print(\"Trained model over soft-MV\")\n",
    "\n",
    "    model_mvhard = clone_model(model_UB) \n",
    "    model_mvhard.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "    model_mvhard.fit(Xstd_train, mv_onehot, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0)\n",
    "    print(\"Trained model over hard-MV\")\n",
    "\n",
    "    model_ds = clone_model(model_UB) \n",
    "    model_ds.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "    model_ds.fit(Xstd_train, ds_labels, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0)\n",
    "    print(\"Trained model over D&S\")\n",
    "\n",
    "    #get representation needed for Raykar\n",
    "    #y_obs_categorical = label_I.y_obs_categ\n",
    "    y_obs_categorical = set_representation(y_obs,'onehot') \n",
    "    \n",
    "    raykarMC = RaykarMC(Xstd_train.shape[1:],y_obs_categorical.shape[-1],T,epochs=1,optimizer=OPT,DTYPE_OP=DTYPE_OP)\n",
    "    raykarMC.define_model('mlp',8,1,BatchN=False,drop=0.2)\n",
    "    logL_hist = raykarMC.stable_train(Xstd_train,y_obs_categorical,batch_size=BATCH_SIZE,max_iter=EPOCHS_BASE,tolerance=TOL)\n",
    "    print(\"Trained model over Raykar\")\n",
    "\n",
    "    #get our representation \n",
    "    r_obs = set_representation(y_obs_categorical,\"repeat\")\n",
    "    print(\"vector of repeats:\\n\",r_obs)\n",
    "    print(\"shape:\",r_obs.shape)\n",
    "    \n",
    "    #pre analysis\n",
    "    M_ffff,annotators_pca = project_and_cluster(y_obs_categorical,return_projected=True,DTYPE_OP=DTYPE_OP)\n",
    "    print(\"Annotators PCA of annotations shape: \",annotators_pca.shape)\n",
    "\n",
    "    aux = [entropy(example)/np.log(r_obs.shape[1]) for example in mv_probas]\n",
    "    print(\"Normalized entropy (0-1) of repeats annotations:\",np.mean(aux))\n",
    "    \n",
    "    gMixture1 = GroupMixtureOpt(Xstd_train.shape[1:],Kl=r_obs.shape[1],M=M_seted,epochs=1,pre_init=5,optimizer=OPT,dtype_op=DTYPE_OP) \n",
    "    gMixture1.define_model(\"mlp\",8,1,BatchN=False,drop=0.2)\n",
    "    gMixture1.lambda_random = False #lambda=1     \n",
    "    logL_hists,i  = gMixture1.multiples_run(1,Xstd_train,r_obs,batch_size=BATCH_SIZE,max_iter=EPOCHS_BASE,tolerance=TOL*2\n",
    "                                       ,cluster=True,bulk_annotators=[y_obs_categorical,annotators_pca])\n",
    "    print(\"Trained model over Ours (1)\")\n",
    "    \n",
    "    gMixture2 = GroupMixtureOpt(Xstd_train.shape[1:],Kl=r_obs.shape[1],M=M_seted,epochs=1,pre_init=5,optimizer=OPT,dtype_op=DTYPE_OP) \n",
    "    gMixture2.define_model(\"mlp\",8,1,BatchN=False,drop=0.2)\n",
    "    gMixture2.lambda_random = True #lambda random\n",
    "    logL_hists,i = gMixture2.multiples_run(1,Xstd_train,r_obs,batch_size=BATCH_SIZE,max_iter=EPOCHS_BASE,tolerance=TOL*2\n",
    "                                       ,cluster=True,bulk_annotators=[y_obs_categorical,annotators_pca])\n",
    "    print(\"Trained model over Ours (2)\")\n",
    "    \n",
    "    gMixture3 = GroupMixtureOpt(Xstd_train.shape[1:],Kl=r_obs.shape[1],M=M_seted,epochs=1,pre_init=5,optimizer=OPT,dtype_op=DTYPE_OP) \n",
    "    gMixture3.define_model(\"mlp\",8,1,BatchN=False,drop=0.2)\n",
    "    gMixture3.lambda_random = True #with lambda random --necessary\n",
    "    logL_hists,i = gMixture3.multiples_run(1,Xstd_train,r_obs,batch_size=BATCH_SIZE,max_iter=EPOCHS_BASE,tolerance=TOL*2\n",
    "                                   ,cluster=True)\n",
    "    print(\"Trained model over Ours (3)\")\n",
    "\n",
    "    \n",
    "    ################## MEASURE PERFORMANCE ##################################\n",
    "    \n",
    "    evaluate = Evaluation_metrics(model_mvsoft,'keras',Xstd_train.shape[0],plot=False)\n",
    "    Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred)\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)\n",
    "    \n",
    "    results_softmv_train += results1\n",
    "    results_softmv_test += results2\n",
    "\n",
    "    evaluate = Evaluation_metrics(model_mvhard,'keras',Xstd_train.shape[0],plot=False)\n",
    "    Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred)\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)\n",
    "    \n",
    "    results_hardmv_train += results1\n",
    "    results_hardmv_test += results2\n",
    "\n",
    "    evaluate = Evaluation_metrics(model_ds,'keras',Xstd_train.shape[0],plot=False)\n",
    "    Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred)\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)\n",
    "    \n",
    "    results_ds_train += results1\n",
    "    results_ds_test += results2\n",
    "    \n",
    "    evaluate = Evaluation_metrics(raykarMC,'raykar',plot=False)\n",
    "    Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "    prob_Yzt = raykarMC.get_confusionM()\n",
    "    prob_Yxt = raykarMC.get_predictions_annot(Xstd_train)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix,y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "    results1_aux = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)\n",
    "    \n",
    "    results_raykar_train += results1\n",
    "    results_raykar_trainA += results1_aux\n",
    "    results_raykar_test += results2\n",
    "\n",
    "    evaluate = Evaluation_metrics(gMixture1,'our1',plot=False) \n",
    "    aux = gMixture1.calculate_extra_components(Xstd_train,y_obs,T=T,calculate_pred_annotator=True)\n",
    "    predictions_m,prob_Gt,prob_Yzt,prob_Yxt =  aux #to evaluate...\n",
    "    Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "    y_o_groups = predictions_m.argmax(axis=-1)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix,y_o=y_obs,yo_pred=prob_Yxt, y_o_groups=y_o_groups)\n",
    "\n",
    "    results1_aux = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "    c_M = gMixture1.get_confusionM()\n",
    "    y_o_groups = gMixture1.get_predictions_groups(Xstd_test).argmax(axis=-1) #obtain p(y^o|x,g=m) and then argmax\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred,conf_pred=c_M, y_o_groups=y_o_groups)\n",
    "    \n",
    "    results_ours1_train  += results1\n",
    "    results_ours1_trainA += results1_aux\n",
    "    results_ours1_testA.append(results2[0])\n",
    "    results_ours1_test.append(results2[1])\n",
    "\n",
    "    evaluate = Evaluation_metrics(gMixture2,'our1',plot=False) \n",
    "    aux = gMixture2.calculate_extra_components(Xstd_train,y_obs,T=T,calculate_pred_annotator=True)\n",
    "    predictions_m,prob_Gt,prob_Yzt,prob_Yxt =  aux #to evaluate...\n",
    "    Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "    y_o_groups = predictions_m.argmax(axis=-1)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix,y_o=y_obs,yo_pred=prob_Yxt, y_o_groups=y_o_groups)\n",
    "\n",
    "    results1_aux = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "    c_M = gMixture2.get_confusionM()\n",
    "    y_o_groups = gMixture2.get_predictions_groups(Xstd_test).argmax(axis=-1) #obtain p(y^o|x,g=m) and then argmax\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred,conf_pred=c_M, y_o_groups=y_o_groups)\n",
    "    \n",
    "    results_ours2_train += results1\n",
    "    results_ours2_trainA += results1_aux\n",
    "    results_ours2_testA.append(results2[0])\n",
    "    results_ours2_test.append(results2[1])\n",
    "\n",
    "    evaluate = Evaluation_metrics(gMixture3,'our1',plot=False) \n",
    "    aux = gMixture3.calculate_extra_components(Xstd_train,y_obs,T=T,calculate_pred_annotator=True)\n",
    "    predictions_m,prob_Gt,prob_Yzt,prob_Yxt =  aux #to evaluate...\n",
    "    Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "    y_o_groups = predictions_m.argmax(axis=-1)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix,y_o=y_obs,yo_pred=prob_Yxt, y_o_groups=y_o_groups)\n",
    "\n",
    "    results1_aux = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "    c_M = gMixture3.get_confusionM()\n",
    "    y_o_groups = gMixture3.get_predictions_groups(Xstd_test).argmax(axis=-1) #obtain p(y^o|x,g=m) and then argmax\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred,conf_pred=c_M, y_o_groups=y_o_groups)\n",
    "\n",
    "    results_ours3_train +=  results1\n",
    "    results_ours3_trainA += results1_aux\n",
    "    results_ours3_testA.append(results2[0])\n",
    "    results_ours3_test.append(results2[1])\n",
    "    \n",
    "    print(\"All Performance Measured\")\n",
    "    \n",
    "del GenerateData\n",
    "gc.collect()\n",
    "\n",
    "#plot measures    \n",
    "get_mean_dataframes(results_softmv_train).to_csv(\"synthetic_softMV_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_softmv_test).to_csv(\"synthetic_softMV_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_hardmv_train).to_csv(\"synthetic_hardMV_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_hardmv_test).to_csv(\"synthetic_hardMV_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_ds_train).to_csv(\"synthetic_DS_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ds_test).to_csv(\"synthetic_DS_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_ds_train).to_csv(\"synthetic_DS_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ds_test).to_csv(\"synthetic_DS_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_raykar_train).to_csv(\"synthetic_Raykar_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_raykar_trainA).to_csv(\"synthetic_Raykar_trainAnn_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_raykar_test).to_csv(\"synthetic_Raykar_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_ours1_train).to_csv(\"synthetic_Ours1_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours1_trainA).to_csv(\"synthetic_Ours1_trainAnn_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours1_test).to_csv(\"synthetic_Ours1_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours1_testA).to_csv(\"synthetic_Ours1_testAux_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_ours2_train).to_csv(\"synthetic_Ours2_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours2_trainA).to_csv(\"synthetic_Ours2_trainAnn_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours2_test).to_csv(\"synthetic_Ours2_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours2_testA).to_csv(\"synthetic_Ours2_testAux_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_ours3_train).to_csv(\"synthetic_Ours3_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours3_trainA).to_csv(\"synthetic_Ours3_trainAnn_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours3_test).to_csv(\"synthetic_Ours3_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours3_testA).to_csv(\"synthetic_Ours3_testAux_s\"+str(scenario)+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[           Accuracy  F1 (micro)\n",
       " 0  Global  0.777923    0.777923]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_softmv_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (data,annotators):  (2292, 10000)\n"
     ]
    }
   ],
   "source": [
    "#delete unlabeled data\n",
    "mask_labeled = np.sum(y_obs != -1,axis=1) != 0\n",
    "Xstd_train = Xstd_train[mask_labeled]\n",
    "Z_train = Z_train[mask_labeled]\n",
    "y_obs = y_obs[mask_labeled]\n",
    "print(\"Shape (data,annotators): \",(y_obs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tesis]",
   "language": "python",
   "name": "conda-env-tesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
