{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation on the Syntetic simmulated data and annotators\n",
    "* batch = 128\n",
    "* delta convergence = 1e-2\n",
    "* Optimizer = ADAM\n",
    "\n",
    "* Our proposed: Pre-train base model with hard-MV (5 epochs?) as Rodrigues: https://github.com/fmpr/CrowdLayer/blob/master/demo-conll-ner-mturk.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fmena/anaconda3/envs/tesis/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras, time, sys, os, gc\n",
    "from keras.models import clone_model\n",
    "\n",
    "DTYPE_OP = 'float32'\n",
    "keras.backend.set_floatx(DTYPE_OP)\n",
    "\n",
    "if DTYPE_OP == 'float64':\n",
    "    keras.backend.set_epsilon(np.finfo(np.float64).eps)\n",
    "elif DTYPE_OP == 'float32':\n",
    "    keras.backend.set_epsilon(np.finfo(np.float32).eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GLOBAL Variables\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS_BASE = 50\n",
    "OPT = 'adam' #optimizer for neural network \n",
    "TOL = 1e-2 #tolerance for relative variation of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2457, 2)\n"
     ]
    }
   ],
   "source": [
    "folder = \".\" #same as refered below..\n",
    "\n",
    "X_train = np.loadtxt(folder+\"/synthetic/simple/datasim_X_train.csv\",delimiter=',')\n",
    "Z_train = np.loadtxt(folder+\"/synthetic/simple/datasim_Z_train.csv\",dtype='int') #groudn truth\n",
    "\n",
    "X_test = np.loadtxt(folder+\"/synthetic/simple/datasim_X_test.csv\",delimiter=',')\n",
    "Z_test = np.loadtxt(folder+\"/synthetic/simple/datasim_Z_test.csv\",dtype='int') #groudn truth\n",
    "\n",
    "print(\"Input shape:\",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2457, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std= StandardScaler(with_mean=True) #matrices sparse with_mean=False\n",
    "std.fit(X_train)\n",
    "Xstd_train = std.transform(X_train)\n",
    "Xstd_test = std.transform(X_test)\n",
    "Xstd_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delta Convergence criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code.learning_models import LogisticRegression_Sklearn,LogisticRegression_Keras,MLP_Keras\n",
    "#deep learning\n",
    "from code.learning_models import default_CNN,default_RNN,default_RNNw_emb,CNN_simple, RNN_simple\n",
    "\n",
    "from code.utils import EarlyStopRelative\n",
    "ourCallback = EarlyStopRelative(monitor='loss',patience=1,min_delta=TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/819 [>.............................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "#upper bound model\n",
    "Z_train_onehot = keras.utils.to_categorical(Z_train)\n",
    "\n",
    "model_UB = MLP_Keras(Xstd_train.shape[1:],Z_train_onehot.shape[1],8,1,BN=False,drop=0.2)\n",
    "\n",
    "model_UB.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "model_UB.fit(Xstd_train,Z_train_onehot,epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0,callbacks=[ourCallback])\n",
    "\n",
    "evaluate = Evaluation_metrics(model_UB,'keras',Xstd_train.shape[0],plot=False)\n",
    "Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred)\n",
    "Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)\n",
    "\n",
    "results1[0].to_csv(\"synthetic_UpperBound_train.csv\",index=False)\n",
    "results2[0].to_csv(\"synthetic_UpperBound_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mean_dataframes(df_values):\n",
    "    if df_values[0].iloc[:,0].dtype == object:\n",
    "        RT = pd.DataFrame(data=None,columns = df_values[0].columns[1:], index= df_values[0].index)\n",
    "    else:\n",
    "        RT = pd.DataFrame(data=None,columns = df_values[0].columns, index= df_values[0].index)\n",
    "        \n",
    "    data = []\n",
    "    for df_value in df_values:\n",
    "        if df_value.iloc[:,0].dtype == object:\n",
    "            data.append( df_value.iloc[:,1:].values )\n",
    "        else:\n",
    "            data.append(df_value.values)\n",
    "    RT[:] = np.mean(data,axis=0)\n",
    "    \n",
    "    if df_values[0].iloc[:,0].dtype == object:\n",
    "        RT.insert(0, \"\", df_values[0].iloc[:,0].values )\n",
    "    return RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code.representation import *\n",
    "from code.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code.baseline import LabelInference\n",
    "from code.baseline import RaykarMC\n",
    "from code.MixtureofGroups import GroupMixtureOpt\n",
    "from code.MixtureofGroups import project_and_cluster,clusterize_annotators\n",
    "from code.evaluation import Evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_seted = 3 #arg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code.generate_data import SinteticData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scenario = 1  #arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Synthetic data is being generated...Done! \n",
      "Shape (data,annotators):  (2457, 100)\n",
      "Classes:  3\n",
      "Iter\tlog-likelihood\tdelta-CM\tdelta-ER\tdelta-LL\n",
      "1 \t -18353.2276559259\n",
      "2 \t -17129.667076434103 \t0.3327\t0.277762\t0.066667\n",
      "3 \t -16869.90643302562 \t0.0791\t0.205824\t0.015164\n",
      "4 \t -16812.19677424611 \t0.0396\t0.144439\t0.003421\n",
      "5 \t -16799.88585212343 \t0.0253\t0.090228\t0.000732\n",
      "6 \t -16796.3632488266 \t0.0154\t0.056213\t0.000210\n",
      "7 \t -16794.99962164132 \t0.0097\t0.033248\t0.000081\n",
      "8 \t -16794.395936528617 \t0.0063\t0.017173\t0.000036\n",
      "9 \t -16794.111072442065 \t0.0042\t0.008658\t0.000017\n",
      "Class marginals\n",
      "[0.33 0.34 0.33]\n",
      "ACC MV on train: 0.7887667887667887\n",
      "ACC D&S on train: 0.9470899470899471\n",
      "Trained model over soft-MV\n",
      "Trained model over hard-MV\n",
      "Trained model over D&S\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Initializing new EM...\n",
      "Betas shape:  (100, 3, 3)\n",
      "Q estimate shape:  (2457, 3)\n",
      "Iter 1/50 \n",
      "M step: done,  E step: done //  (in 0.26 sec)\tlogL: -18208.330\t\n",
      "Iter 2/50 \n",
      "M step: done,  E step: done //  (in 0.06 sec)\tlogL: -16794.684\tTol1: 0.07764\tTol2: 0.28504\t\n",
      "Iter 3/50 \n",
      "M step: done,  E step: done //  (in 0.05 sec)\tlogL: -16460.551\tTol1: 0.01990\tTol2: 0.10105\t\n",
      "Iter 4/50 \n",
      "M step: done,  E step: done //  (in 0.06 sec)\tlogL: -16303.859\tTol1: 0.00952\tTol2: 0.03783\t\n",
      "Iter 5/50 \n",
      "M step: done,  E step: done //  (in 0.06 sec)\tlogL: -16183.801\tTol1: 0.00736\tTol2: 0.01385\t\n",
      "Iter 6/50 \n",
      "M step: done,  E step: done //  (in 0.06 sec)\tlogL: -16078.205\tTol1: 0.00652\tTol2: 0.00567\t\n",
      "Finished training!\n",
      "Trained model over Raykar\n",
      "vector of repeats:\n",
      " [[ 3  0  4]\n",
      " [ 1  3  1]\n",
      " [ 5  0 11]\n",
      " ...\n",
      " [ 6  0  7]\n",
      " [ 9  0  3]\n",
      " [ 5  0  4]]\n",
      "shape: (2457, 3)\n",
      "Bayesian gaussian mixture say is 20 clusters \n",
      "DBSCAN say is 2 clusters\n",
      "Affinity Propagation say is 2 clusters\n",
      "Annotators PCA of annotations shape:  (100, 8)\n",
      "Normalized entropy (0-1) of repeats annotations: 0.6013451623973937\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [1. 1. 1.]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2457, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2457, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 0.31 sec)\tlogL: -24977.763\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.09 sec)\tlogL: -24710.190\tTol1: 0.01071\tTol2: 0.14915\tTol3: 0.00119\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -24360.221\tTol1: 0.01416\tTol2: 0.12472\tTol3: 0.00237\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -23900.141\tTol1: 0.01889\tTol2: 0.12112\tTol3: 0.00421\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -23339.528\tTol1: 0.02346\tTol2: 0.12836\tTol3: 0.00560\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -22738.173\tTol1: 0.02577\tTol2: 0.13770\tTol3: 0.00696\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -22178.580\tTol1: 0.02461\tTol2: 0.14177\tTol3: 0.00790\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21738.831\tTol1: 0.01983\tTol2: 0.13753\tTol3: 0.00711\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21418.753\tTol1: 0.01472\tTol2: 0.12690\tTol3: 0.00621\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -21173.632\tTol1: 0.01144\tTol2: 0.11064\tTol3: 0.00517\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20974.259\tTol1: 0.00942\tTol2: 0.09344\tTol3: 0.00514\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20794.355\tTol1: 0.00858\tTol2: 0.07760\tTol3: 0.00512\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20621.639\tTol1: 0.00831\tTol2: 0.06766\tTol3: 0.00556\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20448.410\tTol1: 0.00840\tTol2: 0.06157\tTol3: 0.00591\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20291.486\tTol1: 0.00767\tTol2: 0.05980\tTol3: 0.00610\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20160.922\tTol1: 0.00643\tTol2: 0.05577\tTol3: 0.00595\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20053.874\tTol1: 0.00531\tTol2: 0.05420\tTol3: 0.00612\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19974.435\tTol1: 0.00396\tTol2: 0.05207\tTol3: 0.00560\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19920.701\tTol1: 0.00269\tTol2: 0.04648\tTol3: 0.00481\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19880.162\tTol1: 0.00204\tTol2: 0.04175\tTol3: 0.00380\t\n",
      "Iter 21/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19851.225\tTol1: 0.00146\tTol2: 0.04167\tTol3: 0.00441\t\n",
      "Iter 22/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19829.276\tTol1: 0.00111\tTol2: 0.04119\tTol3: 0.00454\t\n",
      "Iter 23/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19819.830\tTol1: 0.00048\tTol2: 0.04210\tTol3: 0.00447\t\n",
      "Iter 24/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19807.565\tTol1: 0.00062\tTol2: 0.03403\tTol3: 0.00358\t\n",
      "Iter 25/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19799.406\tTol1: 0.00041\tTol2: 0.03099\tTol3: 0.00282\t\n",
      "Iter 26/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19797.333\tTol1: 0.00010\tTol2: 0.03203\tTol3: 0.00348\t\n",
      "Iter 27/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19793.156\tTol1: 0.00021\tTol2: 0.03187\tTol3: 0.00402\t\n",
      "Iter 28/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19788.601\tTol1: 0.00023\tTol2: 0.02721\tTol3: 0.00294\t\n",
      "Iter 29/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19780.034\tTol1: 0.00043\tTol2: 0.02639\tTol3: 0.00252\t\n",
      "Iter 30/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19775.223\tTol1: 0.00024\tTol2: 0.02577\tTol3: 0.00210\t\n",
      "Iter 31/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19776.354\tTol1: 0.00006\tTol2: 0.02663\tTol3: 0.00259\t\n",
      "Iter 32/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19770.936\tTol1: 0.00027\tTol2: 0.03172\tTol3: 0.00375\t\n",
      "Iter 33/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19766.491\tTol1: 0.00022\tTol2: 0.02648\tTol3: 0.00256\t\n",
      "Iter 34/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19768.233\tTol1: 0.00009\tTol2: 0.02737\tTol3: 0.00223\t\n",
      "Iter 35/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19766.427\tTol1: 0.00009\tTol2: 0.02604\tTol3: 0.00315\t\n",
      "Iter 36/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19768.619\tTol1: 0.00011\tTol2: 0.02482\tTol3: 0.00321\t\n",
      "Iter 37/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19766.929\tTol1: 0.00009\tTol2: 0.01915\tTol3: 0.00212\t\n",
      "Finished training!\n",
      "Trained model over Ours (1)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.03 0.61 0.09]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2457, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2457, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 0.34 sec)\tlogL: -25405.124\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -24803.713\tTol1: 0.02367\tTol2: 0.13402\tTol3: 0.00223\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -24275.149\tTol1: 0.02131\tTol2: 0.08361\tTol3: 0.00276\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -23800.177\tTol1: 0.01957\tTol2: 0.06536\tTol3: 0.00547\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -23336.171\tTol1: 0.01950\tTol2: 0.06600\tTol3: 0.00864\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -22914.430\tTol1: 0.01807\tTol2: 0.07293\tTol3: 0.00974\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -22506.882\tTol1: 0.01779\tTol2: 0.08135\tTol3: 0.01146\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -22138.578\tTol1: 0.01636\tTol2: 0.08775\tTol3: 0.01125\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21813.504\tTol1: 0.01468\tTol2: 0.08940\tTol3: 0.01011\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21521.892\tTol1: 0.01337\tTol2: 0.08816\tTol3: 0.00881\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21280.993\tTol1: 0.01119\tTol2: 0.08513\tTol3: 0.00693\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21077.935\tTol1: 0.00954\tTol2: 0.07767\tTol3: 0.00588\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20902.854\tTol1: 0.00831\tTol2: 0.07169\tTol3: 0.00433\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20760.249\tTol1: 0.00682\tTol2: 0.06526\tTol3: 0.00340\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20641.359\tTol1: 0.00573\tTol2: 0.05533\tTol3: 0.00352\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20541.464\tTol1: 0.00484\tTol2: 0.04413\tTol3: 0.00328\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20466.284\tTol1: 0.00366\tTol2: 0.03694\tTol3: 0.00280\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20392.265\tTol1: 0.00362\tTol2: 0.03104\tTol3: 0.00355\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20333.857\tTol1: 0.00286\tTol2: 0.02946\tTol3: 0.00334\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20278.450\tTol1: 0.00272\tTol2: 0.02429\tTol3: 0.00390\t\n",
      "Iter 21/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20232.070\tTol1: 0.00229\tTol2: 0.02619\tTol3: 0.00378\t\n",
      "Iter 22/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20196.246\tTol1: 0.00177\tTol2: 0.02651\tTol3: 0.00395\t\n",
      "Iter 23/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20162.264\tTol1: 0.00168\tTol2: 0.02720\tTol3: 0.00456\t\n",
      "Iter 24/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20135.173\tTol1: 0.00134\tTol2: 0.02811\tTol3: 0.00472\t\n",
      "Iter 25/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20103.542\tTol1: 0.00157\tTol2: 0.02975\tTol3: 0.00451\t\n",
      "Iter 26/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20082.541\tTol1: 0.00104\tTol2: 0.02948\tTol3: 0.00367\t\n",
      "Iter 27/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20060.873\tTol1: 0.00108\tTol2: 0.03273\tTol3: 0.00465\t\n",
      "Iter 28/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20041.101\tTol1: 0.00099\tTol2: 0.03203\tTol3: 0.00460\t\n",
      "Iter 29/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20020.938\tTol1: 0.00101\tTol2: 0.03126\tTol3: 0.00458\t\n",
      "Iter 30/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20001.907\tTol1: 0.00095\tTol2: 0.03018\tTol3: 0.00439\t\n",
      "Iter 31/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19986.533\tTol1: 0.00077\tTol2: 0.03274\tTol3: 0.00443\t\n",
      "Iter 32/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19974.400\tTol1: 0.00061\tTol2: 0.02946\tTol3: 0.00426\t\n",
      "Iter 33/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19963.705\tTol1: 0.00054\tTol2: 0.03097\tTol3: 0.00466\t\n",
      "Iter 34/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19946.163\tTol1: 0.00088\tTol2: 0.03011\tTol3: 0.00442\t\n",
      "Iter 35/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19937.611\tTol1: 0.00043\tTol2: 0.03235\tTol3: 0.00410\t\n",
      "Iter 36/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19930.153\tTol1: 0.00037\tTol2: 0.03134\tTol3: 0.00428\t\n",
      "Iter 37/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19927.185\tTol1: 0.00015\tTol2: 0.02809\tTol3: 0.00407\t\n",
      "Iter 38/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19918.324\tTol1: 0.00044\tTol2: 0.02743\tTol3: 0.00376\t\n",
      "Iter 39/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19912.536\tTol1: 0.00029\tTol2: 0.02836\tTol3: 0.00409\t\n",
      "Iter 40/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19906.151\tTol1: 0.00032\tTol2: 0.02624\tTol3: 0.00404\t\n",
      "Iter 41/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19901.407\tTol1: 0.00024\tTol2: 0.02412\tTol3: 0.00357\t\n",
      "Iter 42/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19896.333\tTol1: 0.00025\tTol2: 0.02439\tTol3: 0.00410\t\n",
      "Iter 43/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19886.595\tTol1: 0.00049\tTol2: 0.02306\tTol3: 0.00415\t\n",
      "Iter 44/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19879.607\tTol1: 0.00035\tTol2: 0.02014\tTol3: 0.00330\t\n",
      "Iter 45/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19870.695\tTol1: 0.00045\tTol2: 0.01909\tTol3: 0.00312\t\n",
      "Finished training!\n",
      "Trained model over Ours (2)\n",
      "Needed params (units,deep,drop,BatchN?)\n",
      "Clustering Done!\n",
      "Initializing new EM...\n",
      "Pre-train network on 5 epochs... Done!\n",
      "Lambda by group:  [0.68 0.49 0.33]\n",
      "Alphas:  (3,)\n",
      "MV init:  (2457, 3)\n",
      "Betas:  (3, 3, 3)\n",
      "Q estimate:  (2457, 3, 3, 3)\n",
      "Iter 1/50\n",
      "M step: done,  E step: done //  (in 0.38 sec)\tlogL: -23099.678\t\n",
      "Iter 2/50\n",
      "M step: done,  E step: done //  (in 0.08 sec)\tlogL: -22514.638\tTol1: 0.02533\tTol2: 0.15254\tTol3: 0.02809\t\n",
      "Iter 3/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -21997.455\tTol1: 0.02297\tTol2: 0.13735\tTol3: 0.02052\t\n",
      "Iter 4/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -21557.862\tTol1: 0.01998\tTol2: 0.13464\tTol3: 0.01637\t\n",
      "Iter 5/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -21200.808\tTol1: 0.01656\tTol2: 0.12636\tTol3: 0.01338\t\n",
      "Iter 6/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20918.439\tTol1: 0.01332\tTol2: 0.11391\tTol3: 0.01033\t\n",
      "Iter 7/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20698.126\tTol1: 0.01053\tTol2: 0.09905\tTol3: 0.00771\t\n",
      "Iter 8/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20525.594\tTol1: 0.00834\tTol2: 0.08570\tTol3: 0.00606\t\n",
      "Iter 9/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20388.943\tTol1: 0.00666\tTol2: 0.07237\tTol3: 0.00398\t\n",
      "Iter 10/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20278.756\tTol1: 0.00540\tTol2: 0.06084\tTol3: 0.00353\t\n",
      "Iter 11/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -20201.771\tTol1: 0.00380\tTol2: 0.05229\tTol3: 0.00263\t\n",
      "Iter 12/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20139.631\tTol1: 0.00308\tTol2: 0.04516\tTol3: 0.00214\t\n",
      "Iter 13/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20083.379\tTol1: 0.00279\tTol2: 0.04037\tTol3: 0.00172\t\n",
      "Iter 14/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20041.914\tTol1: 0.00206\tTol2: 0.03901\tTol3: 0.00173\t\n",
      "Iter 15/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -20001.284\tTol1: 0.00203\tTol2: 0.03730\tTol3: 0.00190\t\n",
      "Iter 16/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19977.692\tTol1: 0.00118\tTol2: 0.03299\tTol3: 0.00123\t\n",
      "Iter 17/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19951.434\tTol1: 0.00131\tTol2: 0.03346\tTol3: 0.00192\t\n",
      "Iter 18/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19929.588\tTol1: 0.00109\tTol2: 0.02920\tTol3: 0.00121\t\n",
      "Iter 19/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19911.382\tTol1: 0.00091\tTol2: 0.02817\tTol3: 0.00115\t\n",
      "Iter 20/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19900.281\tTol1: 0.00056\tTol2: 0.02622\tTol3: 0.00103\t\n",
      "Iter 21/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19891.585\tTol1: 0.00044\tTol2: 0.02782\tTol3: 0.00165\t\n",
      "Iter 22/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19879.126\tTol1: 0.00063\tTol2: 0.02611\tTol3: 0.00143\t\n",
      "Iter 23/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19869.304\tTol1: 0.00049\tTol2: 0.02609\tTol3: 0.00115\t\n",
      "Iter 24/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19859.601\tTol1: 0.00049\tTol2: 0.02683\tTol3: 0.00154\t\n",
      "Iter 25/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19849.549\tTol1: 0.00051\tTol2: 0.02764\tTol3: 0.00131\t\n",
      "Iter 26/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19843.333\tTol1: 0.00031\tTol2: 0.02883\tTol3: 0.00115\t\n",
      "Iter 27/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19842.735\tTol1: 0.00003\tTol2: 0.02983\tTol3: 0.00149\t\n",
      "Iter 28/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19837.054\tTol1: 0.00029\tTol2: 0.02651\tTol3: 0.00145\t\n",
      "Iter 29/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19828.235\tTol1: 0.00044\tTol2: 0.02469\tTol3: 0.00118\t\n",
      "Iter 30/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19831.187\tTol1: 0.00015\tTol2: 0.02426\tTol3: 0.00090\t\n",
      "Iter 31/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19825.463\tTol1: 0.00029\tTol2: 0.02353\tTol3: 0.00112\t\n",
      "Iter 32/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19818.473\tTol1: 0.00035\tTol2: 0.02283\tTol3: 0.00100\t\n",
      "Iter 33/50\n",
      "M step: done,  E step: done //  (in 0.10 sec)\tlogL: -19819.788\tTol1: 0.00007\tTol2: 0.02120\tTol3: 0.00068\t\n",
      "Iter 34/50\n",
      "M step: done,  E step: done //  (in 0.11 sec)\tlogL: -19819.368\tTol1: 0.00002\tTol2: 0.01886\tTol3: 0.00045\t\n",
      "Finished training!\n",
      "Trained model over Ours (3)\n",
      " 32/819 [>.............................] - ETA: 0sAll Performance Measured\n"
     ]
    }
   ],
   "source": [
    "GenerateData = SinteticData()\n",
    "\n",
    "#CONFUSION MATRIX CHOOSE\n",
    "if scenario == 1 or scenario == 3 or scenario == 4 or scenario == 5 or scenario == 6:\n",
    "    GenerateData.set_probas(asfile=True,file_matrix=folder+'/synthetic/simple/matrix_datasim_normal.csv',file_groups =folder+'/synthetic/simple/groups_datasim_normal.csv')\n",
    "\n",
    "elif scenario == 2 or scenario == 7: #bad MV\n",
    "    GenerateData.set_probas(asfile=True,file_matrix=folder+'/synthetic/simple/matrix_datasim_badMV.csv',file_groups =folder+'/synthetic/simple/groups_datasim_badMV.csv')\n",
    "\n",
    "real_conf_matrix = GenerateData.conf_matrix.copy()\n",
    "\n",
    "\n",
    "#ANNOTATOR DENSITY CHOOSE\n",
    "if scenario == 1 or scenario ==2 or scneario == 3:\n",
    "    Tmax = 100\n",
    "    T_data = 10 \n",
    "    \n",
    "elif scenario == 4 or scenario == 7:\n",
    "    Tmax = 2000\n",
    "    T_data = 20 \n",
    "    \n",
    "elif scenario == 5:\n",
    "    Tmax = 5000\n",
    "    T_data = 25\n",
    "\n",
    "elif scenario == 6:\n",
    "    Tmax = 10000\n",
    "    T_data = 40\n",
    "\n",
    "\n",
    "results_softmv_train = []\n",
    "results_softmv_test = []\n",
    "results_hardmv_train = []\n",
    "results_hardmv_test = []\n",
    "results_ds_train = []\n",
    "results_ds_test = []\n",
    "results_raykar_train = []\n",
    "results_raykar_trainA = []\n",
    "results_raykar_test = []\n",
    "results_ours1_train = []\n",
    "results_ours1_trainA = []\n",
    "results_ours1_test = []\n",
    "results_ours1_testA = []\n",
    "results_ours2_train = []\n",
    "results_ours2_trainA = []\n",
    "results_ours2_test = []\n",
    "results_ours2_testA = []\n",
    "results_ours3_train = []\n",
    "results_ours3_trainA = []\n",
    "results_ours3_test = []\n",
    "results_ours3_testA = []\n",
    "\n",
    "for _ in range(1): #repetitions\n",
    "    print(\"New Synthetic data is being generated...\",flush=True,end='')\n",
    "    if scenario == 3: #soft\n",
    "        y_obs, groups_annot = GenerateData.sintetic_annotate_data(Z_train,Tmax,T_data,deterministic=False,hard=False)\n",
    "    else:\n",
    "        y_obs, groups_annot = GenerateData.sintetic_annotate_data(Z_train,Tmax,T_data,deterministic=False)\n",
    "    print(\"Done! \")\n",
    "    \n",
    "    if len(groups_annot.shape) ==1 or groups_annot.shape[1] ==  1: \n",
    "        groups_annot = keras.utils.to_categorical(groups_annot)  #only if it is hard clustering\n",
    "    confe_matrix = np.tensordot(groups_annot,real_conf_matrix, axes=[[1],[0]])\n",
    "\n",
    "    N,T = y_obs.shape\n",
    "    K = np.max(y_obs)+1 # asumiendo que estan ordenadas\n",
    "    print(\"Shape (data,annotators): \",(N,T))\n",
    "    print(\"Classes: \",K)\n",
    "    \n",
    "    ############# EXECUTE ALGORITHMS #############################\n",
    "\n",
    "    label_I = LabelInference(y_obs,TOL,type_inf = 'all')  #Infer Labels\n",
    "\n",
    "    mv_onehot = label_I.mv_labels('onehot')\n",
    "    mv_probas = label_I.mv_labels('probas')\n",
    "\n",
    "    ds_labels,ds_conf = label_I.DS_labels()\n",
    "    \n",
    "    print(\"ACC MV on train:\",np.mean(mv_onehot.argmax(axis=1)==Z_train))\n",
    "    print(\"ACC D&S on train:\",np.mean(ds_labels.argmax(axis=1)==Z_train))\n",
    "        \n",
    "    model_mvsoft = clone_model(model_UB) \n",
    "    model_mvsoft.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "    model_mvsoft.fit(Xstd_train, mv_probas, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0)\n",
    "    print(\"Trained model over soft-MV\")\n",
    "\n",
    "    model_mvhard = clone_model(model_UB) \n",
    "    model_mvhard.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "    model_mvhard.fit(Xstd_train, mv_onehot, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0)\n",
    "    print(\"Trained model over hard-MV\")\n",
    "\n",
    "    model_ds = clone_model(model_UB) \n",
    "    model_ds.compile(loss='categorical_crossentropy',optimizer=OPT)\n",
    "    model_ds.fit(Xstd_train, ds_labels, epochs=EPOCHS_BASE,batch_size=BATCH_SIZE,verbose=0)\n",
    "    print(\"Trained model over D&S\")\n",
    "\n",
    "    #get representation needed for Raykar\n",
    "    #y_obs_categorical = label_I.y_obs_categ\n",
    "    y_obs_categorical = set_representation(y_obs,'onehot') \n",
    "    \n",
    "    raykarMC = RaykarMC(Xstd_train.shape[1:],y_obs_categorical.shape[-1],T,epochs=1,optimizer=OPT,DTYPE_OP=DTYPE_OP)\n",
    "    raykarMC.define_model('mlp',8,1,BatchN=False,drop=0.2)\n",
    "    logL_hist = raykarMC.stable_train(Xstd_train,y_obs_categorical,batch_size=BATCH_SIZE,max_iter=EPOCHS_BASE,tolerance=TOL)\n",
    "    print(\"Trained model over Raykar\")\n",
    "    \n",
    "    #get our representation \n",
    "    r_obs = set_representation(y_obs_categorical,\"repeat\")\n",
    "    print(\"vector of repeats:\\n\",r_obs)\n",
    "    print(\"shape:\",r_obs.shape)\n",
    "    \n",
    "    #pre analysis\n",
    "    M_ffff,annotators_pca = project_and_cluster(y_obs_categorical,return_projected=True,DTYPE_OP=DTYPE_OP)\n",
    "    print(\"Annotators PCA of annotations shape: \",annotators_pca.shape)\n",
    "\n",
    "    aux = [entropy(example)/np.log(r_obs.shape[1]) for example in mv_probas]\n",
    "    print(\"Normalized entropy (0-1) of repeats annotations:\",np.mean(aux))\n",
    "    \n",
    "    gMixture1 = GroupMixtureOpt(Xstd_train.shape[1:],Kl=r_obs.shape[1],M=M_seted,epochs=1,pre_init=5,optimizer=OPT,dtype_op=DTYPE_OP) \n",
    "    gMixture1.define_model(\"mlp\",8,1,BatchN=False,drop=0.2)\n",
    "    gMixture1.lambda_random = False #lambda=1     \n",
    "    logL_hists,i  = gMixture1.multiples_run(1,Xstd_train,r_obs,batch_size=BATCH_SIZE,max_iter=EPOCHS_BASE,tolerance=TOL*2\n",
    "                                       ,cluster=True,bulk_annotators=[y_obs_categorical,annotators_pca])\n",
    "    print(\"Trained model over Ours (1)\")\n",
    "\n",
    "    \n",
    "    gMixture2 = GroupMixtureOpt(Xstd_train.shape[1:],Kl=r_obs.shape[1],M=M_seted,epochs=1,pre_init=5,optimizer=OPT,dtype_op=DTYPE_OP) \n",
    "    gMixture2.define_model(\"mlp\",8,1,BatchN=False,drop=0.2)\n",
    "    gMixture2.lambda_random = True #lambda random\n",
    "    logL_hists,i = gMixture2.multiples_run(1,Xstd_train,r_obs,batch_size=BATCH_SIZE,max_iter=EPOCHS_BASE,tolerance=TOL*2\n",
    "                                       ,cluster=True,bulk_annotators=[y_obs_categorical,annotators_pca])\n",
    "    print(\"Trained model over Ours (2)\")\n",
    "\n",
    "    \n",
    "    gMixture3 = GroupMixtureOpt(Xstd_train.shape[1:],Kl=r_obs.shape[1],M=M_seted,epochs=1,pre_init=5,optimizer=OPT,dtype_op=DTYPE_OP) \n",
    "    gMixture3.define_model(\"mlp\",8,1,BatchN=False,drop=0.2)\n",
    "    gMixture3.lambda_random = True #with lambda random --necessary\n",
    "    logL_hists,i = gMixture3.multiples_run(1,Xstd_train,r_obs,batch_size=BATCH_SIZE,max_iter=EPOCHS_BASE,tolerance=TOL*2\n",
    "                                   ,cluster=True)\n",
    "    print(\"Trained model over Ours (3)\")\n",
    "    \n",
    "    ################## MEASURE PERFORMANCE ##################################\n",
    "    \n",
    "    evaluate = Evaluation_metrics(model_mvsoft,'keras',Xstd_train.shape[0],plot=False)\n",
    "    Z_train_p = evaluate.tested_model.predict(Xstd_train)\n",
    "    prob_Yzt = get_confusionM(Z_train_p,y_obs_categorical)\n",
    "    Z_train_pred = Z_train_p.argmax(axis=1)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix)\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)\n",
    "    \n",
    "    results_softmv_train += results1\n",
    "    results_softmv_test += results2\n",
    "\n",
    "    evaluate = Evaluation_metrics(model_mvhard,'keras',Xstd_train.shape[0],plot=False)\n",
    "    Z_train_p = evaluate.tested_model.predict(Xstd_train)\n",
    "    prob_Yzt = get_confusionM(Z_train_p,y_obs_categorical)\n",
    "    Z_train_pred = Z_train_p.argmax(axis=1)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix)\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)\n",
    "    \n",
    "    results_hardmv_train += results1\n",
    "    results_hardmv_test += results2\n",
    "\n",
    "    evaluate = Evaluation_metrics(model_ds,'keras',Xstd_train.shape[0],plot=False)\n",
    "    Z_train_p = evaluate.tested_model.predict(Xstd_train)\n",
    "    prob_Yzt = get_confusionM(Z_train_p,y_obs_categorical)\n",
    "    Z_train_pred = Z_train_p.argmax(axis=1)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix)\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)\n",
    "    \n",
    "    results_ds_train += results1\n",
    "    results_ds_test += results2\n",
    "    \n",
    "    evaluate = Evaluation_metrics(raykarMC,'raykar',plot=False)\n",
    "    Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "    prob_Yzt = raykarMC.get_confusionM()\n",
    "    prob_Yxt = raykarMC.get_predictions_annot(Xstd_train)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix,y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "    results1_aux = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred)\n",
    "    \n",
    "    results_raykar_train += results1\n",
    "    results_raykar_trainA += results1_aux\n",
    "    results_raykar_test += results2\n",
    "\n",
    "    evaluate = Evaluation_metrics(gMixture1,'our1',plot=False) \n",
    "    aux = gMixture1.calculate_extra_components(Xstd_train,y_obs,T=T,calculate_pred_annotator=True)\n",
    "    predictions_m,prob_Gt,prob_Yzt,prob_Yxt =  aux #to evaluate...\n",
    "    Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "    y_o_groups = predictions_m.argmax(axis=-1)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix,y_o=y_obs,yo_pred=prob_Yxt, y_o_groups=y_o_groups)\n",
    "\n",
    "    results1_aux = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "    c_M = gMixture1.get_confusionM()\n",
    "    y_o_groups = gMixture1.get_predictions_groups(Xstd_test).argmax(axis=-1) #obtain p(y^o|x,g=m) and then argmax\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred,conf_pred=c_M, y_o_groups=y_o_groups)\n",
    "    \n",
    "    results_ours1_train  += results1\n",
    "    results_ours1_trainA += results1_aux\n",
    "    results_ours1_testA.append(results2[0])\n",
    "    results_ours1_test.append(results2[1])\n",
    "\n",
    "    evaluate = Evaluation_metrics(gMixture2,'our1',plot=False) \n",
    "    aux = gMixture2.calculate_extra_components(Xstd_train,y_obs,T=T,calculate_pred_annotator=True)\n",
    "    predictions_m,prob_Gt,prob_Yzt,prob_Yxt =  aux #to evaluate...\n",
    "    Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "    y_o_groups = predictions_m.argmax(axis=-1)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix,y_o=y_obs,yo_pred=prob_Yxt, y_o_groups=y_o_groups)\n",
    "\n",
    "    results1_aux = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "    c_M = gMixture2.get_confusionM()\n",
    "    y_o_groups = gMixture2.get_predictions_groups(Xstd_test).argmax(axis=-1) #obtain p(y^o|x,g=m) and then argmax\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred,conf_pred=c_M, y_o_groups=y_o_groups)\n",
    "    \n",
    "    results_ours2_train += results1\n",
    "    results_ours2_trainA += results1_aux\n",
    "    results_ours2_testA.append(results2[0])\n",
    "    results_ours2_test.append(results2[1])\n",
    "\n",
    "    evaluate = Evaluation_metrics(gMixture3,'our1',plot=False) \n",
    "    aux = gMixture3.calculate_extra_components(Xstd_train,y_obs,T=T,calculate_pred_annotator=True)\n",
    "    predictions_m,prob_Gt,prob_Yzt,prob_Yxt =  aux #to evaluate...\n",
    "    Z_train_pred = evaluate.tested_model.predict_classes(Xstd_train)\n",
    "    y_o_groups = predictions_m.argmax(axis=-1)\n",
    "    results1 = evaluate.calculate_metrics(Z=Z_train,Z_pred=Z_train_pred,conf_pred=prob_Yzt,conf_true=confe_matrix,y_o=y_obs,yo_pred=prob_Yxt, y_o_groups=y_o_groups)\n",
    "\n",
    "    results1_aux = evaluate.calculate_metrics(y_o=y_obs,yo_pred=prob_Yxt)\n",
    "\n",
    "    c_M = gMixture3.get_confusionM()\n",
    "    y_o_groups = gMixture3.get_predictions_groups(Xstd_test).argmax(axis=-1) #obtain p(y^o|x,g=m) and then argmax\n",
    "    Z_test_pred = evaluate.tested_model.predict_classes(Xstd_test)\n",
    "    results2 = evaluate.calculate_metrics(Z=Z_test,Z_pred=Z_test_pred,conf_pred=c_M, y_o_groups=y_o_groups)\n",
    "\n",
    "    results_ours3_train +=  results1\n",
    "    results_ours3_trainA += results1_aux\n",
    "    results_ours3_testA.append(results2[0])\n",
    "    results_ours3_test.append(results2[1])\n",
    "        \n",
    "    print(\"All Performance Measured\")\n",
    "    \n",
    "del GenerateData\n",
    "gc.collect()\n",
    "\n",
    "#plot measures    \n",
    "get_mean_dataframes(results_softmv_train).to_csv(\"synthetic_softMV_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_softmv_test).to_csv(\"synthetic_softMV_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_hardmv_train).to_csv(\"synthetic_hardMV_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_hardmv_test).to_csv(\"synthetic_hardMV_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_ds_train).to_csv(\"synthetic_DS_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ds_test).to_csv(\"synthetic_DS_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_ds_train).to_csv(\"synthetic_DS_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ds_test).to_csv(\"synthetic_DS_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_raykar_train).to_csv(\"synthetic_Raykar_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_raykar_trainA).to_csv(\"synthetic_Raykar_trainAnn_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_raykar_test).to_csv(\"synthetic_Raykar_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_ours1_train).to_csv(\"synthetic_Ours1_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours1_trainA).to_csv(\"synthetic_Ours1_trainAnn_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours1_test).to_csv(\"synthetic_Ours1_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours1_testA).to_csv(\"synthetic_Ours1_testAux_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_ours2_train).to_csv(\"synthetic_Ours2_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours2_trainA).to_csv(\"synthetic_Ours2_trainAnn_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours2_test).to_csv(\"synthetic_Ours2_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours2_testA).to_csv(\"synthetic_Ours2_testAux_s\"+str(scenario)+\".csv\",index=False)\n",
    "\n",
    "get_mean_dataframes(results_ours3_train).to_csv(\"synthetic_Ours3_train_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours3_trainA).to_csv(\"synthetic_Ours3_trainAnn_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours3_test).to_csv(\"synthetic_Ours3_test_s\"+str(scenario)+\".csv\",index=False)\n",
    "get_mean_dataframes(results_ours3_testA).to_csv(\"synthetic_Ours3_testAux_s\"+str(scenario)+\".csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tesis]",
   "language": "python",
   "name": "conda-env-tesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
